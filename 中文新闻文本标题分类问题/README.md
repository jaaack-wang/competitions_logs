# 介绍

这里的notebook是我自己参加比赛所用的代码。是个14类的分类问题。如果一个文件的日期后没有注明epoch，那么都是5个epoch。batch size也不一样，具体见notebooks。

- `bare_cnn_20220322`是简单的cnn分类器，没有加载任何预训练好的词向量。最后测试集准确度：82.1%。之前也试过只用随机抽选的5万例子来训练，结果是76.1%；10万的结果是78.5%。需要注意的是，notebook里，测试集65万多，验证集10万多，训练完模型的准确度一个96%多，一个92%多，但是测试集准确度仍然不过82.1%。这说明测试集的部分数据分布，可能与训练集的很不同。如果要在测试集取得另一个层次的好成绩，估计要么用预训练的词向量，要么用预训练好的模型，后者当然会更香。
- `bare_bilstm_20220322`是简单的双向LSTM模型。最后测试集准确度：83.1%。
- `ernie-1.0_ptm_20220322`是百度Ernie-1.0预训练模型。最后测试集准确度: 86.3%。
- `bert-wwm-chinese-20220323-2-epchos`是bert-wwm-chinese预训练模型，只训练了两个epchos。最后测试集准确度却有88.1%。
- `bert-wwm-chinese-20220323`同上，但训练了5个epchos。（另外，我也调高了batch size）。最后测试集准确度：86.2%。看来是在训练集上过拟合了。
- `roberta-wwm-ext-20220323-1-epoch`只训练了1个epoch。结果：85.7%。
- `erniegram-20220323-3-epochs`训练了3个epoch，batch size调到128。最后测试集准确度：85.8%。
- `bert-wwm-chinese-20220324`不区分训练集和验证集，直接全拿来训练。最后测试集准确度：88.3%。
- `bert-wwm-chinese-20220324-10-epochs-64-batchsize`: 同上，训练了10个epoches + 64的batch size。结果：87.7%。64 batch size很慢很慢，慎用。


## 赛题介绍

本次比赛为新闻标题文本分类 ，要求参赛者基于原始新闻标题文本数据训练模型，从而判断其所属类别。

## 数据简介

THUCNews是根据新浪新闻RSS订阅频道2005~2011年间的历史数据筛选过滤生成，包含74万篇新闻文档（2.19 GB），均为UTF-8纯文本格式。在原始新浪新闻分类体系的基础上，重新整合划分出14个候选分类类别：财经、彩票、房产、股票、家居、教育、科技、社会、时尚、时政、体育、星座、游戏、娱乐。

## 数据说明

为了使参赛者快速进入比赛核心阶段，我们已将训练集按照“标签ID+\t+标签+\t+原文标题”的格式抽取出来，参赛者可以直接根据新闻标题进行文本分类任务，希望参赛者能够给出自己的解决方案。数据集可以点[这里](https://aistudio.baidu.com/aistudio/datasetdetail/12701)下载。

### 训练集格式
标签ID+\t+标签+\t+原文标题

### 测试集格式
原文标题