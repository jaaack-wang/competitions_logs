# 介绍

这里的notebook是我自己参加比赛所用的代码。是个14类的分类问题。如果一个文件的日期后没有注明epoch，那么都是5个epoch。batch size也不一样，具体见notebooks。

- `bare_cnn_20220322`是简单的cnn分类器，没有加载任何预训练好的词向量。最后测试集准确度：82.1%。之前也试过只用随机抽选的5万例子来训练，结果是76.1%；10万的结果是78.5%。需要注意的是，notebook里，测试集65万多，验证集10万多，训练完模型的准确度一个96%多，一个92%多，但是测试集准确度仍然不过82.1%。这说明测试集的部分数据分布，可能与训练集的很不同。如果要在测试集取得另一个层次的好成绩，估计要么用预训练的词向量，要么用预训练好的模型，后者当然会更香。
- `bare_bilstm_20220322`是简单的双向LSTM模型。最后测试集准确度：83.1%。
- `ernie-1.0_ptm_20220322`是百度Ernie-1.0预训练模型。最后测试集准确度: 86.3%。
- `bert-wwm-chinese-20220323-2-epchos`是bert-wwm-chinese预训练模型，只训练了两个epchos。最后测试集准确度却有88.1%。
- `bert-wwm-chinese-20220323`同上，但训练了5个epchos。（另外，我也调高了batch size）。最后测试集准确度：86.2%。看来是在训练集上过拟合了。
- `roberta-wwm-ext-20220323-1-epoch`只训练了1个epoch。结果：85.7%。
- `erniegram-20220323-3-epochs`训练了3个epoch，batch size调到128。最后测试集准确度：85.8%。
- `bert-wwm-chinese-20220324`不区分训练集和验证集，直接全拿来训练。最后测试集准确度：88.3%。
- `bert-wwm-chinese-20220324-10-epochs-64-batchsize`: 同上，训练了10个epoches + 64的batch size。结果：87.7%。64 batch size很慢很慢，慎用。
- `cnn+pretrained_embd-20220325-10-epochs`是用预训练词向量+cnn来训练。试了10epochs，20个epochs，甚至30个epochs，加或者没加earlystopping，加或者没加dropout，等等，最后的结果，无论怎么过拟合，都在80%～84%区间内。

- `roberta-wwm-ext-large-20220326-4-epochs`, 最后的测试集准确度：88.9%。
	- 最好的战绩：89.5%。max_seq_length = 64; batch_size = 128，训练了半个epoch + 2个epochs（停了又训练）。同样的设定，训练了半个epoch不到（被中途终止了），结果是87.0%。完整训练了一次2个epochs，结果稍微下降，为88.2(接着再训练了一个epoch，训练集准确度快达到97%，测试集的结果为88.9%）。由于我没有设置random seed，所以运行我的代码，每次结果都会稍微不同。但由此可见，预训练模型finetune带来的效果提升不如模型本身给力。如果不花心思去调参，结果不会有很大的不同。但是这个模型本身，稍微训练一下，轻轻松松就比我之前最好的结果，稳定高出了4-5%。


## 赛题介绍

本次比赛为新闻标题文本分类 ，要求参赛者基于原始新闻标题文本数据训练模型，从而判断其所属类别。

## 数据简介

THUCNews是根据新浪新闻RSS订阅频道2005~2011年间的历史数据筛选过滤生成，包含74万篇新闻文档（2.19 GB），均为UTF-8纯文本格式。在原始新浪新闻分类体系的基础上，重新整合划分出14个候选分类类别：财经、彩票、房产、股票、家居、教育、科技、社会、时尚、时政、体育、星座、游戏、娱乐。

## 数据说明

为了使参赛者快速进入比赛核心阶段，我们已将训练集按照“标签ID+\t+标签+\t+原文标题”的格式抽取出来，参赛者可以直接根据新闻标题进行文本分类任务，希望参赛者能够给出自己的解决方案。数据集可以点[这里](https://aistudio.baidu.com/aistudio/datasetdetail/12701)下载。

### 训练集格式
标签ID+\t+标签+\t+原文标题

### 测试集格式
原文标题