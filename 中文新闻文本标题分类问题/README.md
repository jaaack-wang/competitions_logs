# 介绍

这里的notebook是我自己参加比赛所用的代码。是个14类的分类问题。如果一个文件的日期后没有注明epoch，那么都是5个epoch。batch size也不一样，具体见notebooks。

- `bare_cnn_20220322`是简单的cnn分类器，没有加载任何预训练好的词向量。最后测试集准确度：82.1%。之前也试过只用随机抽选的5万例子来训练，结果是76.1%；10万的结果是78.5%。需要注意的是，notebook里，测试集65万多，验证集10万多，训练完模型的准确度一个96%多，一个92%多，但是测试集准确度仍然不过82.1%。这说明测试集的部分数据分布，可能与训练集的很不同。如果要在测试集取得另一个层次的好成绩，估计要么用预训练的词向量，要么用预训练好的模型，后者当然会更香。
- `bare_bilstm_20220322`是简单的双向LSTM模型。最后测试集准确度：83.1%。
- `ernie-1.0_ptm_20220322`是百度Ernie-1.0预训练模型。最后测试集准确度: 86.3%。
- `bert-wwm-chinese-20220323-2-epchos`是bert-wwm-chinese预训练模型，只训练了两个epchos。最后测试集准确度却有88.1%。
- `bert-wwm-chinese-20220323`同上，但训练了5个epchos。（另外，我也调高了batch size）。最后测试集准确度：86.2%。看来是在训练集上过拟合了。
- `roberta-wwm-ext-20220323-1-epoch`只训练了1个epoch。结果：85.7%。
- `erniegram-20220323-3-epochs`训练了3个epoch，batch size调到128。最后测试集准确度：85.8%。
- `bert-wwm-chinese-20220324`不区分训练集和验证集，直接全拿来训练。最后测试集准确度：88.3%。
- `bert-wwm-chinese-20220324-10-epochs-64-batchsize`: 同上，训练了10个epoches + 64的batch size。结果：87.7%。64 batch size很慢很慢，慎用。
- `cnn+pretrained_embd-20220325-10-epochs`是用预训练词向量+cnn来训练。试了10epochs，20个epochs，甚至30个epochs，加或者没加earlystopping，加或者没加dropout，等等，最后的结果，无论怎么过拟合，都在80%～84%区间内。
	- 我的理解是，这跟模型的向量维度有关。我用的预训练向量维度为300，可能远高于实际需要的维度数。由于维度过高，那么拟合测试集就很简单，简单说有无数解，导致比较难将模型的参数正好训练到想要的某个方向。预训练模型虽然维度也大，但它的整体向量已经分布在一个较好的区域，更接近于我们需要的分布。猜测而已。
	- 另外一种可能是，由于所用的预训练词向量词汇量很大，一些在测试集出现的词汇在训练集没出现，也有对应的（未经调试的）词向量，而不是简单的<UNK>。这些词向量有可能拖了后腿。不过，这也仍然只是猜测而已。

## 赛题介绍

本次比赛为新闻标题文本分类 ，要求参赛者基于原始新闻标题文本数据训练模型，从而判断其所属类别。

## 数据简介

THUCNews是根据新浪新闻RSS订阅频道2005~2011年间的历史数据筛选过滤生成，包含74万篇新闻文档（2.19 GB），均为UTF-8纯文本格式。在原始新浪新闻分类体系的基础上，重新整合划分出14个候选分类类别：财经、彩票、房产、股票、家居、教育、科技、社会、时尚、时政、体育、星座、游戏、娱乐。

## 数据说明

为了使参赛者快速进入比赛核心阶段，我们已将训练集按照“标签ID+\t+标签+\t+原文标题”的格式抽取出来，参赛者可以直接根据新闻标题进行文本分类任务，希望参赛者能够给出自己的解决方案。数据集可以点[这里](https://aistudio.baidu.com/aistudio/datasetdetail/12701)下载。

### 训练集格式
标签ID+\t+标签+\t+原文标题

### 测试集格式
原文标题