{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-25T21:30:09.021438Z",
     "iopub.status.busy": "2022-03-25T21:30:09.021171Z",
     "iopub.status.idle": "2022-03-25T21:30:09.026196Z",
     "shell.execute_reply": "2022-03-25T21:30:09.025741Z",
     "shell.execute_reply.started": "2022-03-25T21:30:09.021416Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_dataset(fpath, test=False, num_row_to_skip=0):\n",
    "    data = open(fpath)\n",
    "    for _ in range(num_row_to_skip):\n",
    "        next(data)\n",
    "\n",
    "    out = []\n",
    "\n",
    "    if test:\n",
    "        for line in data:\n",
    "            out.append(line.strip())\n",
    "        \n",
    "        return out\n",
    "\n",
    "    idx_to_label = {}\n",
    "    for line in data:\n",
    "        line = line.strip().split('\\t')\n",
    "        if len(line) == 3:\n",
    "            idx, label, text = line\n",
    "            idx = int(idx)\n",
    "            idx_to_label[idx] = label\n",
    "            out.append([text, idx])\n",
    "    \n",
    "    return out, idx_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-25T21:30:09.026959Z",
     "iopub.status.busy": "2022-03-25T21:30:09.026804Z",
     "iopub.status.idle": "2022-03-25T21:30:10.537532Z",
     "shell.execute_reply": "2022-03-25T21:30:10.537081Z",
     "shell.execute_reply.started": "2022-03-25T21:30:09.026940Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(752471,\n",
       " [['上证50ETF净申购突增', 0], ['交银施罗德保本基金将发行', 0]],\n",
       " {0: '财经',\n",
       "  1: '彩票',\n",
       "  2: '房产',\n",
       "  3: '股票',\n",
       "  4: '家居',\n",
       "  5: '教育',\n",
       "  6: '科技',\n",
       "  7: '社会',\n",
       "  8: '时尚',\n",
       "  9: '时政',\n",
       "  10: '体育',\n",
       "  11: '星座',\n",
       "  12: '游戏',\n",
       "  13: '娱乐'})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set, idx_to_label = load_dataset('./data/data12701/Train.txt')\n",
    "len(train_set), train_set[:2], idx_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T21:30:10.539041Z",
     "iopub.status.busy": "2022-03-25T21:30:10.538693Z",
     "iopub.status.idle": "2022-03-25T21:30:11.163048Z",
     "shell.execute_reply": "2022-03-25T21:30:11.162463Z",
     "shell.execute_reply.started": "2022-03-25T21:30:10.539004Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# split the train_set into train and dev sets\n",
    "from random import shuffle, seed\n",
    "\n",
    "seed(43)\n",
    "shuffle(train_set)\n",
    "\n",
    "train_set, dev_set = train_set[:652471], train_set[652471: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-25T21:30:11.164459Z",
     "iopub.status.busy": "2022-03-25T21:30:11.163964Z",
     "iopub.status.idle": "2022-03-25T21:30:11.209759Z",
     "shell.execute_reply": "2022-03-25T21:30:11.209336Z",
     "shell.execute_reply.started": "2022-03-25T21:30:11.164435Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83599, ['北京君太百货璀璨秋色 满100省353020元', '教育部：小学高年级将开始学习性知识'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = load_dataset('./data/data12701/Test.txt', test=True)\n",
    "len(test_set), test_set[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Transform text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-25T21:30:11.210818Z",
     "iopub.status.busy": "2022-03-25T21:30:11.210524Z",
     "iopub.status.idle": "2022-03-25T21:30:21.562960Z",
     "shell.execute_reply": "2022-03-25T21:30:21.562254Z",
     "shell.execute_reply.started": "2022-03-25T21:30:11.210797Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-26 05:30:12,804] [    INFO] - Loading token embedding...\n",
      "W0326 05:30:17.112741  5713 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1\n",
      "W0326 05:30:17.118315  5713 device_context.cc:465] device: 0, cuDNN Version: 7.6.\n",
      "[2022-03-26 05:30:21,462] [    INFO] - Finish loading embedding vector.\n",
      "[2022-03-26 05:30:21,504] [    INFO] - Token Embedding info:             \n",
      "Unknown index: 635963             \n",
      "Unknown token: [UNK]             \n",
      "Padding index: 635964             \n",
      "Padding token: [PAD]             \n",
      "Shape :[635965, 300]\n"
     ]
    }
   ],
   "source": [
    "from paddlenlp.datasets import MapDataset\n",
    "from paddle.io import BatchSampler, DataLoader\n",
    "from paddlenlp.data import Pad, Stack, Tuple\n",
    "from paddlenlp.embeddings import TokenEmbedding\n",
    "import jieba\n",
    "\n",
    "\n",
    "name = \"w2v.baidu_encyclopedia.target.word-word.dim300\"\n",
    "token_embedding = TokenEmbedding(embedding_name=name)\n",
    "vocab = token_embedding.vocab \n",
    "\n",
    "\n",
    "def text_encoder(text):\n",
    "    tks = jieba.lcut(text)\n",
    "    return [vocab[tk] for tk in tks]\n",
    "\n",
    "\n",
    "def example_converter(example, text_encoder):\n",
    "    text, label = example\n",
    "    text_ids = text_encoder(text)\n",
    "    return text_ids, label\n",
    "\n",
    "\n",
    "def get_trans_fn(text_encoder=text_encoder):\n",
    "    return lambda ex: example_converter(ex, text_encoder)\n",
    "\n",
    "\n",
    "def get_batchify_fn():\n",
    "    \n",
    "    batchify_fn = lambda samples, fn=Tuple(\n",
    "        Pad(axis=0, pad_val=vocab['[PAD]']), \n",
    "        Stack(dtype=\"int64\")\n",
    "    ): fn(samples)\n",
    "    \n",
    "    return batchify_fn\n",
    "\n",
    "\n",
    "def create_dataloader(dataset, \n",
    "                      trans_fn, \n",
    "                      batchify_fn, \n",
    "                      test=False,\n",
    "                      batch_size=128, \n",
    "                      shuffle=True, \n",
    "                      sampler=BatchSampler):\n",
    "    \n",
    "    if test:\n",
    "        dataset = [[d, 0] for d in dataset]\n",
    "\n",
    "    if not isinstance(dataset, MapDataset):\n",
    "        dataset = MapDataset(dataset)\n",
    "        \n",
    "    dataset.map(trans_fn)\n",
    "    batch_sampler = sampler(dataset, \n",
    "                            shuffle=shuffle, \n",
    "                            batch_size=batch_size)\n",
    "    \n",
    "    dataloder = DataLoader(dataset, \n",
    "                           batch_sampler=batch_sampler, \n",
    "                           collate_fn=batchify_fn)\n",
    "    \n",
    "    return dataloder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-25T21:30:21.564686Z",
     "iopub.status.busy": "2022-03-25T21:30:21.564374Z",
     "iopub.status.idle": "2022-03-25T21:30:22.376220Z",
     "shell.execute_reply": "2022-03-25T21:30:22.375592Z",
     "shell.execute_reply.started": "2022-03-25T21:30:21.564661Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "trans_fn = get_trans_fn(text_encoder)\n",
    "batchify_fn = get_batchify_fn()\n",
    "train_loader = create_dataloader(train_set, trans_fn, batchify_fn, batch_size=batch_size)\n",
    "dev_loader = create_dataloader(dev_set, trans_fn, batchify_fn, batch_size=batch_size)\n",
    "test_loader = create_dataloader(test_set, trans_fn, batchify_fn, shuffle=False, test=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-25T21:30:22.378457Z",
     "iopub.status.busy": "2022-03-25T21:30:22.378018Z",
     "iopub.status.idle": "2022-03-25T21:30:22.387602Z",
     "shell.execute_reply": "2022-03-25T21:30:22.387036Z",
     "shell.execute_reply.started": "2022-03-25T21:30:22.378432Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import paddle \n",
    "import paddle.nn as nn\n",
    "import paddle.nn.functional as F\n",
    "\n",
    "\n",
    "class CNN(nn.Layer):\n",
    "\n",
    "    def __init__(self, \n",
    "                 embedding,\n",
    "                 output_dim,\n",
    "                 embedding_dim,\n",
    "                 dropout=0.5, \n",
    "                 padding_idx=vocab['[PAD]'],\n",
    "                 num_filter=256,\n",
    "                 filter_sizes=(3,),\n",
    "                 hidden_dim=50,\n",
    "                 activation=nn.ReLU()):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = embedding\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.convs = nn.LayerList([\n",
    "            nn.Conv1D(\n",
    "                in_channels=embedding_dim,\n",
    "                out_channels=num_filter,\n",
    "                kernel_size=fz\n",
    "            ) for fz in filter_sizes\n",
    "        ])\n",
    "        self.fc1 = nn.Linear(len(filter_sizes) * num_filter, hidden_dim)\n",
    "        self.act = activation\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def encoder(self, embd):\n",
    "        embd = embd.transpose((0,2,1))\n",
    "        conved = [self.act(conv(embd)) for conv in self.convs]\n",
    "        max_pooled = [F.adaptive_max_pool1d(conv, output_size=1).squeeze(2) for conv in conved]\n",
    "        pooled_concat = paddle.concat(max_pooled, axis=1)\n",
    "        return pooled_concat\n",
    "\n",
    "    def forward(self, text_ids):\n",
    "        embd = self.dropout(self.embedding(text_ids))\n",
    "        encoded = self.encoder(embd)\n",
    "        hidden = self.dropout(self.act(self.fc1(encoded)))\n",
    "        logits = self.fc2(hidden)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T21:30:22.388897Z",
     "iopub.status.busy": "2022-03-25T21:30:22.388483Z",
     "iopub.status.idle": "2022-03-25T21:30:22.394648Z",
     "shell.execute_reply": "2022-03-25T21:30:22.394167Z",
     "shell.execute_reply.started": "2022-03-25T21:30:22.388863Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from paddlenlp.transformers import LinearDecayWithWarmup\n",
    "\n",
    "epoch = 30\n",
    "weight_decay = 0.001\n",
    "warmup_proportion = 0.01\n",
    "lr_scheduler = LinearDecayWithWarmup(5e-3, len(train_loader) * epoch,\n",
    "                                         warmup_proportion)\n",
    "\n",
    "def get_model(model):\n",
    "    decay_params = [\n",
    "        p.name for n, p in model.named_parameters()\n",
    "        if not any(nd in n for nd in [\"bias\", \"norm\"])\n",
    "    ]\n",
    "    optimizer = paddle.optimizer.AdamW(\n",
    "    parameters=model.parameters(), \n",
    "    learning_rate=lr_scheduler, \n",
    "    weight_decay=weight_decay, \n",
    "    apply_decay_param_fun=lambda x: x in decay_params)\n",
    "\n",
    "    criterion = paddle.nn.CrossEntropyLoss()\n",
    "\n",
    "    model = paddle.Model(model)\n",
    "    metric = paddle.metric.Accuracy()\n",
    "    model.prepare(optimizer, criterion, metric)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T21:30:22.395761Z",
     "iopub.status.busy": "2022-03-25T21:30:22.395395Z",
     "iopub.status.idle": "2022-03-25T21:30:22.402008Z",
     "shell.execute_reply": "2022-03-25T21:30:22.401570Z",
     "shell.execute_reply.started": "2022-03-25T21:30:22.395739Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = CNN(token_embedding, len(idx_to_label), 300)\n",
    "model = get_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-25T21:30:22.403071Z",
     "iopub.status.busy": "2022-03-25T21:30:22.402688Z",
     "iopub.status.idle": "2022-03-25T21:44:36.505045Z",
     "shell.execute_reply": "2022-03-25T21:44:36.504222Z",
     "shell.execute_reply.started": "2022-03-25T21:30:22.403051Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous steps.\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.638 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 100/638 - loss: 0.9639 - acc: 0.4530 - 132ms/step\n",
      "step 200/638 - loss: 0.6233 - acc: 0.6103 - 126ms/step\n",
      "step 300/638 - loss: 0.5796 - acc: 0.6876 - 125ms/step\n",
      "step 400/638 - loss: 0.4914 - acc: 0.7321 - 124ms/step\n",
      "step 500/638 - loss: 0.4557 - acc: 0.7610 - 123ms/step\n",
      "step 600/638 - loss: 0.4493 - acc: 0.7813 - 123ms/step\n",
      "step 638/638 - loss: 0.2977 - acc: 0.7876 - 122ms/step\n",
      "save checkpoint at /home/aistudio/ckpt/0\n",
      "Eval begin...\n",
      "step 98/98 - loss: 0.2864 - acc: 0.9158 - 108ms/step\n",
      "Eval samples: 100000\n",
      "Epoch 2/30\n",
      "step 100/638 - loss: 0.3053 - acc: 0.9033 - 124ms/step\n",
      "step 200/638 - loss: 0.2993 - acc: 0.9036 - 120ms/step\n",
      "step 300/638 - loss: 0.3253 - acc: 0.9032 - 119ms/step\n",
      "step 400/638 - loss: 0.4150 - acc: 0.9043 - 119ms/step\n",
      "step 500/638 - loss: 0.3626 - acc: 0.9045 - 118ms/step\n",
      "step 600/638 - loss: 0.2961 - acc: 0.9049 - 118ms/step\n",
      "step 638/638 - loss: 0.3896 - acc: 0.9050 - 118ms/step\n",
      "Eval begin...\n",
      "step 98/98 - loss: 0.2572 - acc: 0.9246 - 105ms/step\n",
      "Eval samples: 100000\n",
      "Epoch 3/30\n",
      "step 100/638 - loss: 0.2545 - acc: 0.9227 - 123ms/step\n",
      "step 200/638 - loss: 0.2688 - acc: 0.9221 - 120ms/step\n",
      "step 300/638 - loss: 0.3035 - acc: 0.9214 - 122ms/step\n",
      "step 400/638 - loss: 0.2451 - acc: 0.9213 - 121ms/step\n",
      "step 500/638 - loss: 0.3054 - acc: 0.9210 - 121ms/step\n",
      "step 600/638 - loss: 0.3019 - acc: 0.9208 - 120ms/step\n",
      "step 638/638 - loss: 0.1886 - acc: 0.9207 - 119ms/step\n",
      "Eval begin...\n",
      "step 98/98 - loss: 0.2244 - acc: 0.9252 - 105ms/step\n",
      "Eval samples: 100000\n",
      "Epoch 4/30\n",
      "step 100/638 - loss: 0.2417 - acc: 0.9334 - 123ms/step\n",
      "step 200/638 - loss: 0.1981 - acc: 0.9315 - 120ms/step\n",
      "step 300/638 - loss: 0.2083 - acc: 0.9311 - 119ms/step\n",
      "step 400/638 - loss: 0.1966 - acc: 0.9308 - 119ms/step\n",
      "step 500/638 - loss: 0.2607 - acc: 0.9306 - 119ms/step\n",
      "step 600/638 - loss: 0.2513 - acc: 0.9301 - 119ms/step\n",
      "step 638/638 - loss: 0.2498 - acc: 0.9298 - 118ms/step\n",
      "Eval begin...\n",
      "step 98/98 - loss: 0.3077 - acc: 0.9261 - 104ms/step\n",
      "Eval samples: 100000\n",
      "Epoch 5/30\n",
      "step 100/638 - loss: 0.1923 - acc: 0.9390 - 123ms/step\n",
      "step 200/638 - loss: 0.1632 - acc: 0.9386 - 120ms/step\n",
      "step 300/638 - loss: 0.2002 - acc: 0.9382 - 119ms/step\n",
      "step 400/638 - loss: 0.2008 - acc: 0.9378 - 119ms/step\n",
      "step 500/638 - loss: 0.2374 - acc: 0.9372 - 118ms/step\n",
      "step 600/638 - loss: 0.2634 - acc: 0.9365 - 118ms/step\n",
      "step 638/638 - loss: 0.2175 - acc: 0.9364 - 117ms/step\n",
      "Eval begin...\n",
      "step 98/98 - loss: 0.3179 - acc: 0.9244 - 105ms/step\n",
      "Eval samples: 100000\n",
      "Epoch 6/30\n",
      "step 100/638 - loss: 0.1863 - acc: 0.9444 - 128ms/step\n",
      "step 200/638 - loss: 0.1534 - acc: 0.9443 - 124ms/step\n",
      "step 300/638 - loss: 0.1761 - acc: 0.9434 - 122ms/step\n",
      "step 400/638 - loss: 0.1878 - acc: 0.9427 - 121ms/step\n",
      "step 500/638 - loss: 0.2230 - acc: 0.9420 - 121ms/step\n",
      "step 600/638 - loss: 0.2129 - acc: 0.9414 - 120ms/step\n",
      "step 638/638 - loss: 0.2260 - acc: 0.9411 - 119ms/step\n",
      "Eval begin...\n",
      "step 98/98 - loss: 0.3278 - acc: 0.9241 - 105ms/step\n",
      "Eval samples: 100000\n",
      "Epoch 7/30\n",
      "step 100/638 - loss: 0.1643 - acc: 0.9492 - 123ms/step\n",
      "step 200/638 - loss: 0.1951 - acc: 0.9479 - 120ms/step\n",
      "step 300/638 - loss: 0.2020 - acc: 0.9473 - 119ms/step\n",
      "step 400/638 - loss: 0.1426 - acc: 0.9470 - 119ms/step\n",
      "step 500/638 - loss: 0.1744 - acc: 0.9464 - 118ms/step\n",
      "step 600/638 - loss: 0.2028 - acc: 0.9457 - 118ms/step\n",
      "step 638/638 - loss: 0.1488 - acc: 0.9456 - 117ms/step\n",
      "Eval begin...\n",
      "step 98/98 - loss: 0.2866 - acc: 0.9250 - 104ms/step\n",
      "Eval samples: 100000\n",
      "Epoch 8/30\n",
      "step 100/638 - loss: 0.1258 - acc: 0.9517 - 120ms/step\n",
      "step 200/638 - loss: 0.1738 - acc: 0.9512 - 119ms/step\n",
      "step 300/638 - loss: 0.1465 - acc: 0.9509 - 118ms/step\n",
      "step 400/638 - loss: 0.1687 - acc: 0.9501 - 118ms/step\n",
      "step 500/638 - loss: 0.1484 - acc: 0.9493 - 118ms/step\n",
      "step 600/638 - loss: 0.1500 - acc: 0.9489 - 118ms/step\n",
      "step 638/638 - loss: 0.1283 - acc: 0.9489 - 117ms/step\n",
      "Eval begin...\n",
      "step 98/98 - loss: 0.2860 - acc: 0.9257 - 114ms/step\n",
      "Eval samples: 100000\n",
      "Epoch 8: Early stopping.\n",
      "Best checkpoint has been saved at /home/aistudio/ckpt/best_model\n",
      "save checkpoint at /home/aistudio/ckpt/final\n"
     ]
    }
   ],
   "source": [
    "from paddle.callbacks import EarlyStopping\n",
    "\n",
    "earlystop = EarlyStopping(patience=5, save_best_model=True)\n",
    "\n",
    "# model.fit(train_loader, epochs=epoch, verbose=2, log_freq=100)\n",
    "model.fit(train_loader, dev_loader, \n",
    "          epochs=epoch, callbacks=[earlystop], \n",
    "          verbose=2, log_freq=100, save_dir=\"ckpt\", save_freq=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-25T21:44:36.507162Z",
     "iopub.status.busy": "2022-03-25T21:44:36.506370Z",
     "iopub.status.idle": "2022-03-25T21:44:45.061146Z",
     "shell.execute_reply": "2022-03-25T21:44:45.060585Z",
     "shell.execute_reply.started": "2022-03-25T21:44:36.507106Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict begin...\n",
      "step 82/82 [==============================] - ETA: 14s - 175ms/ste - ETA: 11s - 143ms/ste - ETA: 10s - 132ms/ste - ETA: 9s - 126ms/ste - ETA: 8s - 122ms/st - ETA: 8s - 120ms/st - ETA: 8s - 119ms/st - ETA: 7s - 117ms/st - ETA: 7s - 115ms/st - ETA: 7s - 114ms/st - ETA: 6s - 113ms/st - ETA: 6s - 112ms/st - ETA: 6s - 111ms/st - ETA: 5s - 111ms/st - ETA: 5s - 110ms/st - ETA: 5s - 110ms/st - ETA: 5s - 110ms/st - ETA: 5s - 110ms/st - ETA: 4s - 109ms/st - ETA: 4s - 109ms/st - ETA: 4s - 109ms/st - ETA: 4s - 109ms/st - ETA: 3s - 108ms/st - ETA: 3s - 108ms/st - ETA: 3s - 108ms/st - ETA: 3s - 107ms/st - ETA: 3s - 107ms/st - ETA: 2s - 107ms/st - ETA: 2s - 107ms/st - ETA: 2s - 107ms/st - ETA: 2s - 107ms/st - ETA: 1s - 107ms/st - ETA: 1s - 106ms/st - ETA: 1s - 106ms/st - ETA: 1s - 106ms/st - ETA: 1s - 106ms/st - ETA: 0s - 106ms/st - ETA: 0s - 106ms/st - ETA: 0s - 106ms/st - ETA: 0s - 106ms/st - 104ms/step          \n",
      "Predict samples: 83599\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import paddle.nn.functional as F\n",
    "\n",
    "\n",
    "predictions = []\n",
    "logits = model.predict(test_loader)\n",
    "\n",
    "for batch in logits[0]:\n",
    "    batch = paddle.to_tensor(batch)\n",
    "    probs = F.softmax(batch, axis=1)\n",
    "    preds = paddle.argmax(probs, axis=1).numpy().tolist()\n",
    "    predictions.extend(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-25T21:44:45.062543Z",
     "iopub.status.busy": "2022-03-25T21:44:45.062275Z",
     "iopub.status.idle": "2022-03-25T21:44:45.090728Z",
     "shell.execute_reply": "2022-03-25T21:44:45.090287Z",
     "shell.execute_reply.started": "2022-03-25T21:44:45.062519Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('result.txt', 'w') as f:\n",
    "    f.write(idx_to_label[predictions[0]])\n",
    "    for p in predictions[1:]:\n",
    "        f.write('\\n' + idx_to_label[p])\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
