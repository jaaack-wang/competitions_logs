{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-23T17:43:00.703550Z",
     "iopub.status.busy": "2022-03-23T17:43:00.702793Z",
     "iopub.status.idle": "2022-03-23T17:43:00.708988Z",
     "shell.execute_reply": "2022-03-23T17:43:00.708328Z",
     "shell.execute_reply.started": "2022-03-23T17:43:00.703515Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_dataset(fpath, test=False, num_row_to_skip=0):\n",
    "    data = open(fpath)\n",
    "    for _ in range(num_row_to_skip):\n",
    "        next(data)\n",
    "\n",
    "    out = []\n",
    "\n",
    "    if test:\n",
    "        for line in data:\n",
    "            out.append(line.strip())\n",
    "        \n",
    "        return out\n",
    "\n",
    "    idx_to_label = {}\n",
    "    for line in data:\n",
    "        line = line.strip().split('\\t')\n",
    "        if len(line) == 3:\n",
    "            idx, label, text = line\n",
    "            idx = int(idx)\n",
    "            idx_to_label[idx] = label\n",
    "            out.append([text, idx])\n",
    "    \n",
    "    return out, idx_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-23T17:43:00.710661Z",
     "iopub.status.busy": "2022-03-23T17:43:00.710405Z",
     "iopub.status.idle": "2022-03-23T17:43:02.364856Z",
     "shell.execute_reply": "2022-03-23T17:43:02.364257Z",
     "shell.execute_reply.started": "2022-03-23T17:43:00.710638Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(752471,\n",
       " [['上证50ETF净申购突增', 0], ['交银施罗德保本基金将发行', 0]],\n",
       " {0: '财经',\n",
       "  1: '彩票',\n",
       "  2: '房产',\n",
       "  3: '股票',\n",
       "  4: '家居',\n",
       "  5: '教育',\n",
       "  6: '科技',\n",
       "  7: '社会',\n",
       "  8: '时尚',\n",
       "  9: '时政',\n",
       "  10: '体育',\n",
       "  11: '星座',\n",
       "  12: '游戏',\n",
       "  13: '娱乐'})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set, idx_to_label = load_dataset('./data/data12701/Train.txt')\n",
    "len(train_set), train_set[:2], idx_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-23T17:43:02.366299Z",
     "iopub.status.busy": "2022-03-23T17:43:02.365839Z",
     "iopub.status.idle": "2022-03-23T17:43:03.203361Z",
     "shell.execute_reply": "2022-03-23T17:43:03.202676Z",
     "shell.execute_reply.started": "2022-03-23T17:43:02.366270Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# split the train_set into train and dev sets\n",
    "from random import shuffle, seed\n",
    "\n",
    "seed(43)\n",
    "shuffle(train_set)\n",
    "\n",
    "train_set, dev_set = train_set[:652471], train_set[652471: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-23T17:43:03.205223Z",
     "iopub.status.busy": "2022-03-23T17:43:03.204865Z",
     "iopub.status.idle": "2022-03-23T17:43:03.252009Z",
     "shell.execute_reply": "2022-03-23T17:43:03.251380Z",
     "shell.execute_reply.started": "2022-03-23T17:43:03.205194Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83599, ['北京君太百货璀璨秋色 满100省353020元', '教育部：小学高年级将开始学习性知识'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = load_dataset('./data/data12701/Test.txt', test=True)\n",
    "len(test_set), test_set[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Transform text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-23T17:43:03.253441Z",
     "iopub.status.busy": "2022-03-23T17:43:03.252985Z",
     "iopub.status.idle": "2022-03-23T17:43:05.090315Z",
     "shell.execute_reply": "2022-03-23T17:43:05.089702Z",
     "shell.execute_reply.started": "2022-03-23T17:43:03.253414Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-24 01:43:04,962] [    INFO] - Downloading https://paddlenlp.bj.bcebos.com/models/transformers/ernie/vocab.txt and saved to /home/aistudio/.paddlenlp/models/ernie-1.0\n",
      "[2022-03-24 01:43:04,965] [    INFO] - Downloading vocab.txt from https://paddlenlp.bj.bcebos.com/models/transformers/ernie/vocab.txt\n",
      "100%|██████████| 90/90 [00:00<00:00, 2881.80it/s]\n"
     ]
    }
   ],
   "source": [
    "from paddlenlp.datasets import MapDataset\n",
    "from paddle.io import BatchSampler, DataLoader\n",
    "from paddlenlp.data import Pad, Stack, Tuple\n",
    "from paddlenlp import transformers\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "MODEL_NAME = \"ernie-1.0\"\n",
    "tokenizer = transformers.ErnieTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "\n",
    "def example_converter(example, tokenizer, max_seq_length=128):\n",
    "    \n",
    "    text, label = example\n",
    "    encoded_inputs = tokenizer(text=text, max_seq_len=max_seq_length)\n",
    "    input_ids = encoded_inputs[\"input_ids\"]\n",
    "    token_type_ids = encoded_inputs[\"token_type_ids\"]\n",
    "    label = np.array([label], dtype=\"int64\")\n",
    "    return input_ids, token_type_ids, label\n",
    "\n",
    "\n",
    "def get_trans_fn(text_encoder, max_seq_length=128):\n",
    "    return lambda ex: example_converter(ex, text_encoder, max_seq_length)\n",
    "\n",
    "\n",
    "def get_batchify_fn(tokenizer=tokenizer):\n",
    "    \n",
    "    batchify_fn = lambda samples, fn=Tuple(\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id), \n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_type_id),\n",
    "        Stack(dtype=\"int64\")\n",
    "    ): fn(samples)\n",
    "    \n",
    "    return batchify_fn\n",
    "\n",
    "\n",
    "def create_dataloader(dataset, \n",
    "                      trans_fn, \n",
    "                      batchify_fn, \n",
    "                      test=False,\n",
    "                      batch_size=128, \n",
    "                      shuffle=True, \n",
    "                      sampler=BatchSampler):\n",
    "    \n",
    "    if test:\n",
    "        dataset = [[d, 0] for d in dataset]\n",
    "\n",
    "    if not isinstance(dataset, MapDataset):\n",
    "        dataset = MapDataset(dataset)\n",
    "        \n",
    "    dataset.map(trans_fn)\n",
    "    batch_sampler = sampler(dataset, \n",
    "                            shuffle=shuffle, \n",
    "                            batch_size=batch_size)\n",
    "    \n",
    "    dataloder = DataLoader(dataset, \n",
    "                           batch_sampler=batch_sampler, \n",
    "                           collate_fn=batchify_fn)\n",
    "    \n",
    "    return dataloder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-23T17:43:05.091719Z",
     "iopub.status.busy": "2022-03-23T17:43:05.091423Z",
     "iopub.status.idle": "2022-03-23T17:43:06.082876Z",
     "shell.execute_reply": "2022-03-23T17:43:06.082189Z",
     "shell.execute_reply.started": "2022-03-23T17:43:05.091692Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_seq_length = 16; batch_size = 256\n",
    "trans_fn = get_trans_fn(tokenizer, max_seq_length)\n",
    "batchify_fn = get_batchify_fn()\n",
    "train_loader = create_dataloader(train_set, trans_fn, batchify_fn, batch_size=batch_size)\n",
    "dev_loader = create_dataloader(dev_set, trans_fn, batchify_fn, batch_size=batch_size)\n",
    "test_loader = create_dataloader(test_set, trans_fn, batchify_fn, shuffle=False, test=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-23T17:44:02.677163Z",
     "iopub.status.busy": "2022-03-23T17:44:02.676258Z",
     "iopub.status.idle": "2022-03-23T17:44:04.418700Z",
     "shell.execute_reply": "2022-03-23T17:44:04.417985Z",
     "shell.execute_reply.started": "2022-03-23T17:44:02.677119Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-24 01:44:02,683] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/ernie-1.0/ernie_v1_chn_base.pdparams\n"
     ]
    }
   ],
   "source": [
    "import paddle \n",
    "from paddlenlp.transformers import LinearDecayWithWarmup\n",
    "\n",
    "\n",
    "model = transformers.ErnieForSequenceClassification.from_pretrained(MODEL_NAME, num_classes=len(idx_to_label))\n",
    "\n",
    "learning_rate = 5e-5; epochs = 5\n",
    "warmup_proportion = 0.1; weight_decay = 0.01\n",
    "num_training_steps = len(train_loader) * epochs\n",
    "lr_scheduler = LinearDecayWithWarmup(learning_rate, num_training_steps, warmup_proportion)\n",
    "optimizer = paddle.optimizer.AdamW(\n",
    "    learning_rate=lr_scheduler,\n",
    "    parameters=model.parameters(),\n",
    "    weight_decay=weight_decay,\n",
    "    apply_decay_param_fun=lambda x: x in [\n",
    "        p.name for n, p in model.named_parameters()\n",
    "        if not any(nd in n for nd in [\"bias\", \"norm\"])\n",
    "    ])\n",
    "\n",
    "criterion = paddle.nn.loss.CrossEntropyLoss()\n",
    "metric = paddle.metric.Accuracy()\n",
    "\n",
    "\n",
    "@paddle.no_grad()\n",
    "def evaluate(model, criterion, metric, data_loader):\n",
    "    \"\"\"\n",
    "    Given a dataset, it evals model and computes the metric.\n",
    "\n",
    "    Args:\n",
    "        model(obj:`paddle.nn.Layer`): A model to classify texts.\n",
    "        data_loader(obj:`paddle.io.DataLoader`): The dataset loader which generates batches.\n",
    "        criterion(obj:`paddle.nn.Layer`): It can compute the loss.\n",
    "        metric(obj:`paddle.metric.Metric`): The evaluation metric.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    metric.reset()\n",
    "    losses = []\n",
    "    for batch in data_loader:\n",
    "        input_ids, token_type_ids, labels = batch\n",
    "        logits = model(input_ids, token_type_ids)\n",
    "        loss = criterion(logits, labels)\n",
    "        losses.append(loss.numpy())\n",
    "        correct = metric.compute(logits, labels)\n",
    "        metric.update(correct)\n",
    "        accu = metric.accumulate()\n",
    "    print(\"eval loss: %.5f, accu: %.5f\" % (np.mean(losses), accu))\n",
    "    model.train()\n",
    "    metric.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-23T17:44:07.357114Z",
     "iopub.status.busy": "2022-03-23T17:44:07.356619Z",
     "iopub.status.idle": "2022-03-23T18:42:19.021379Z",
     "shell.execute_reply": "2022-03-23T18:42:19.020463Z",
     "shell.execute_reply.started": "2022-03-23T17:44:07.357076Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 200, epoch: 1, batch: 200, loss: 0.87745, acc: 0.36180\n",
      "global step 400, epoch: 1, batch: 400, loss: 0.39251, acc: 0.60229\n",
      "global step 600, epoch: 1, batch: 600, loss: 0.37153, acc: 0.69855\n",
      "global step 800, epoch: 1, batch: 800, loss: 0.44869, acc: 0.75039\n",
      "global step 1000, epoch: 1, batch: 1000, loss: 0.30168, acc: 0.78260\n",
      "global step 1200, epoch: 1, batch: 1200, loss: 0.27262, acc: 0.80453\n",
      "global step 1400, epoch: 1, batch: 1400, loss: 0.24838, acc: 0.82132\n",
      "global step 1600, epoch: 1, batch: 1600, loss: 0.20881, acc: 0.83400\n",
      "global step 1800, epoch: 1, batch: 1800, loss: 0.21726, acc: 0.84434\n",
      "global step 2000, epoch: 1, batch: 2000, loss: 0.16612, acc: 0.85281\n",
      "global step 2200, epoch: 1, batch: 2200, loss: 0.24940, acc: 0.85981\n",
      "global step 2400, epoch: 1, batch: 2400, loss: 0.24411, acc: 0.86590\n",
      "eval loss: 0.18752, accu: 0.94085\n",
      "global step 2600, epoch: 2, batch: 51, loss: 0.15898, acc: 0.94462\n",
      "global step 2800, epoch: 2, batch: 251, loss: 0.17325, acc: 0.94472\n",
      "global step 3000, epoch: 2, batch: 451, loss: 0.12420, acc: 0.94445\n",
      "global step 3200, epoch: 2, batch: 651, loss: 0.21749, acc: 0.94465\n",
      "global step 3400, epoch: 2, batch: 851, loss: 0.14245, acc: 0.94438\n",
      "global step 3600, epoch: 2, batch: 1051, loss: 0.20514, acc: 0.94453\n",
      "global step 3800, epoch: 2, batch: 1251, loss: 0.16528, acc: 0.94482\n",
      "global step 4000, epoch: 2, batch: 1451, loss: 0.17200, acc: 0.94498\n",
      "global step 4200, epoch: 2, batch: 1651, loss: 0.12132, acc: 0.94509\n",
      "global step 4400, epoch: 2, batch: 1851, loss: 0.16707, acc: 0.94535\n",
      "global step 4600, epoch: 2, batch: 2051, loss: 0.18946, acc: 0.94563\n",
      "global step 4800, epoch: 2, batch: 2251, loss: 0.15116, acc: 0.94578\n",
      "global step 5000, epoch: 2, batch: 2451, loss: 0.13634, acc: 0.94580\n",
      "eval loss: 0.16355, accu: 0.94753\n",
      "global step 5200, epoch: 3, batch: 102, loss: 0.12349, acc: 0.95588\n",
      "global step 5400, epoch: 3, batch: 302, loss: 0.20643, acc: 0.95814\n",
      "global step 5600, epoch: 3, batch: 502, loss: 0.12638, acc: 0.95816\n",
      "global step 5800, epoch: 3, batch: 702, loss: 0.07687, acc: 0.95752\n",
      "global step 6000, epoch: 3, batch: 902, loss: 0.09130, acc: 0.95762\n",
      "global step 6200, epoch: 3, batch: 1102, loss: 0.10906, acc: 0.95797\n",
      "global step 6400, epoch: 3, batch: 1302, loss: 0.13534, acc: 0.95838\n",
      "global step 6600, epoch: 3, batch: 1502, loss: 0.10847, acc: 0.95845\n",
      "global step 6800, epoch: 3, batch: 1702, loss: 0.13541, acc: 0.95867\n",
      "global step 7000, epoch: 3, batch: 1902, loss: 0.10118, acc: 0.95873\n",
      "global step 7200, epoch: 3, batch: 2102, loss: 0.15052, acc: 0.95873\n",
      "global step 7400, epoch: 3, batch: 2302, loss: 0.11150, acc: 0.95881\n",
      "global step 7600, epoch: 3, batch: 2502, loss: 0.09390, acc: 0.95897\n",
      "eval loss: 0.16180, accu: 0.94884\n",
      "global step 7800, epoch: 4, batch: 153, loss: 0.05885, acc: 0.96946\n",
      "global step 8000, epoch: 4, batch: 353, loss: 0.09254, acc: 0.96995\n",
      "global step 8200, epoch: 4, batch: 553, loss: 0.04845, acc: 0.96949\n",
      "global step 8400, epoch: 4, batch: 753, loss: 0.12212, acc: 0.96903\n",
      "global step 8600, epoch: 4, batch: 953, loss: 0.06061, acc: 0.96868\n",
      "global step 8800, epoch: 4, batch: 1153, loss: 0.07495, acc: 0.96862\n",
      "global step 9000, epoch: 4, batch: 1353, loss: 0.07598, acc: 0.96863\n",
      "global step 9200, epoch: 4, batch: 1553, loss: 0.08146, acc: 0.96889\n",
      "global step 9400, epoch: 4, batch: 1753, loss: 0.11412, acc: 0.96888\n",
      "global step 9600, epoch: 4, batch: 1953, loss: 0.07245, acc: 0.96892\n",
      "global step 9800, epoch: 4, batch: 2153, loss: 0.11657, acc: 0.96894\n",
      "global step 10000, epoch: 4, batch: 2353, loss: 0.07589, acc: 0.96891\n",
      "eval loss: 0.16377, accu: 0.94999\n",
      "global step 10200, epoch: 5, batch: 4, loss: 0.11063, acc: 0.97754\n",
      "global step 10400, epoch: 5, batch: 204, loss: 0.04406, acc: 0.97666\n",
      "global step 10600, epoch: 5, batch: 404, loss: 0.10323, acc: 0.97616\n",
      "global step 10800, epoch: 5, batch: 604, loss: 0.09155, acc: 0.97583\n",
      "global step 11000, epoch: 5, batch: 804, loss: 0.08665, acc: 0.97557\n",
      "global step 11200, epoch: 5, batch: 1004, loss: 0.05458, acc: 0.97564\n",
      "global step 11400, epoch: 5, batch: 1204, loss: 0.09757, acc: 0.97558\n",
      "global step 11600, epoch: 5, batch: 1404, loss: 0.06292, acc: 0.97580\n",
      "global step 11800, epoch: 5, batch: 1604, loss: 0.06827, acc: 0.97588\n",
      "global step 12000, epoch: 5, batch: 1804, loss: 0.05719, acc: 0.97592\n",
      "global step 12200, epoch: 5, batch: 2004, loss: 0.03001, acc: 0.97579\n",
      "global step 12400, epoch: 5, batch: 2204, loss: 0.09003, acc: 0.97589\n",
      "global step 12600, epoch: 5, batch: 2404, loss: 0.05295, acc: 0.97595\n",
      "eval loss: 0.17147, accu: 0.95035\n"
     ]
    }
   ],
   "source": [
    "import paddle.nn.functional as F\n",
    "\n",
    "\n",
    "global_step = 0\n",
    "paddle.set_device(\"gpu\")\n",
    "for epoch in range(1, epochs + 1):\n",
    "    for step, batch in enumerate(train_loader, start=1):\n",
    "        input_ids, segment_ids, labels = batch\n",
    "        logits = model(input_ids, segment_ids)\n",
    "        loss = criterion(logits, labels)\n",
    "        probs = F.softmax(logits, axis=1)\n",
    "        correct = metric.compute(probs, labels)\n",
    "        metric.update(correct)\n",
    "        acc = metric.accumulate()\n",
    "\n",
    "        global_step += 1\n",
    "        if global_step % 200 == 0 :\n",
    "            print(\"global step %d, epoch: %d, batch: %d, loss: %.5f, acc: %.5f\" % (global_step, epoch, step, loss, acc))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.clear_grad()\n",
    "    evaluate(model, criterion, metric, dev_loader)\n",
    "\n",
    "\n",
    "model.save_pretrained('/home/aistudio/checkpoint')\n",
    "tokenizer.save_pretrained('/home/aistudio/checkpoint')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-23T18:42:19.039391Z",
     "iopub.status.busy": "2022-03-23T18:42:19.038791Z",
     "iopub.status.idle": "2022-03-23T18:42:54.412195Z",
     "shell.execute_reply": "2022-03-23T18:42:54.411515Z",
     "shell.execute_reply.started": "2022-03-23T18:42:19.039350Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "for batch in test_loader:\n",
    "    input_ids, segment_ids, _ = batch\n",
    "    logits = model(input_ids, segment_ids)\n",
    "    probs = F.softmax(logits, axis=1)\n",
    "    preds = paddle.argmax(probs, axis=1).numpy().tolist()\n",
    "    predictions.extend(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-23T18:42:54.414853Z",
     "iopub.status.busy": "2022-03-23T18:42:54.414315Z",
     "iopub.status.idle": "2022-03-23T18:42:54.442975Z",
     "shell.execute_reply": "2022-03-23T18:42:54.442458Z",
     "shell.execute_reply.started": "2022-03-23T18:42:54.414822Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('result.txt', 'w') as f:\n",
    "    f.write(idx_to_label[predictions[0]])\n",
    "    for p in predictions[1:]:\n",
    "        f.write('\\n' + idx_to_label[p])\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-23T18:42:54.444092Z",
     "iopub.status.busy": "2022-03-23T18:42:54.443839Z",
     "iopub.status.idle": "2022-03-23T18:42:54.874491Z",
     "shell.execute_reply": "2022-03-23T18:42:54.873705Z",
     "shell.execute_reply.started": "2022-03-23T18:42:54.444069Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: result.txt (deflated 89%)\n"
     ]
    }
   ],
   "source": [
    "!zip result.txt.zip result.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
