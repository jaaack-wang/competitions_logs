{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-23T20:41:30.506695Z",
     "iopub.status.busy": "2022-03-23T20:41:30.506444Z",
     "iopub.status.idle": "2022-03-23T20:41:30.513486Z",
     "shell.execute_reply": "2022-03-23T20:41:30.512737Z",
     "shell.execute_reply.started": "2022-03-23T20:41:30.506660Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_dataset(fpath, test=False, num_row_to_skip=0):\n",
    "    data = open(fpath)\n",
    "    for _ in range(num_row_to_skip):\n",
    "        next(data)\n",
    "\n",
    "    out = []\n",
    "\n",
    "    if test:\n",
    "        for line in data:\n",
    "            out.append(line.strip())\n",
    "        \n",
    "        return out\n",
    "\n",
    "    idx_to_label = {}\n",
    "    for line in data:\n",
    "        line = line.strip().split('\\t')\n",
    "        if len(line) == 3:\n",
    "            idx, label, text = line\n",
    "            idx = int(idx)\n",
    "            idx_to_label[idx] = label\n",
    "            out.append([text, idx])\n",
    "    \n",
    "    return out, idx_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-23T20:41:30.514800Z",
     "iopub.status.busy": "2022-03-23T20:41:30.514565Z",
     "iopub.status.idle": "2022-03-23T20:41:32.182447Z",
     "shell.execute_reply": "2022-03-23T20:41:32.181839Z",
     "shell.execute_reply.started": "2022-03-23T20:41:30.514777Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(752471,\n",
       " [['上证50ETF净申购突增', 0], ['交银施罗德保本基金将发行', 0]],\n",
       " {0: '财经',\n",
       "  1: '彩票',\n",
       "  2: '房产',\n",
       "  3: '股票',\n",
       "  4: '家居',\n",
       "  5: '教育',\n",
       "  6: '科技',\n",
       "  7: '社会',\n",
       "  8: '时尚',\n",
       "  9: '时政',\n",
       "  10: '体育',\n",
       "  11: '星座',\n",
       "  12: '游戏',\n",
       "  13: '娱乐'})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set, idx_to_label = load_dataset('./data/data12701/Train.txt')\n",
    "len(train_set), train_set[:2], idx_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-23T20:41:32.183883Z",
     "iopub.status.busy": "2022-03-23T20:41:32.183463Z",
     "iopub.status.idle": "2022-03-23T20:41:32.972413Z",
     "shell.execute_reply": "2022-03-23T20:41:32.971727Z",
     "shell.execute_reply.started": "2022-03-23T20:41:32.183856Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# split the train_set into train and dev sets\n",
    "from random import shuffle, seed\n",
    "\n",
    "seed(43)\n",
    "shuffle(train_set)\n",
    "\n",
    "train_set, dev_set = train_set[:652471], train_set[652471: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-23T20:41:32.973977Z",
     "iopub.status.busy": "2022-03-23T20:41:32.973508Z",
     "iopub.status.idle": "2022-03-23T20:41:33.019216Z",
     "shell.execute_reply": "2022-03-23T20:41:33.018662Z",
     "shell.execute_reply.started": "2022-03-23T20:41:32.973950Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83599, ['北京君太百货璀璨秋色 满100省353020元', '教育部：小学高年级将开始学习性知识'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = load_dataset('./data/data12701/Test.txt', test=True)\n",
    "len(test_set), test_set[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Transform text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-23T20:41:33.098062Z",
     "iopub.status.busy": "2022-03-23T20:41:33.097222Z",
     "iopub.status.idle": "2022-03-23T20:41:34.982443Z",
     "shell.execute_reply": "2022-03-23T20:41:34.981496Z",
     "shell.execute_reply.started": "2022-03-23T20:41:33.098018Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-24 04:41:34,840] [    INFO] - Downloading https://paddlenlp.bj.bcebos.com/models/transformers/roberta_base/vocab.txt and saved to /home/aistudio/.paddlenlp/models/roberta-wwm-ext\n",
      "[2022-03-24 04:41:34,843] [    INFO] - Downloading vocab.txt from https://paddlenlp.bj.bcebos.com/models/transformers/roberta_base/vocab.txt\n",
      "100%|██████████| 107/107 [00:00<00:00, 3023.75it/s]\n"
     ]
    }
   ],
   "source": [
    "from paddlenlp.datasets import MapDataset\n",
    "from paddle.io import BatchSampler, DataLoader\n",
    "from paddlenlp.data import Pad, Stack, Tuple\n",
    "from paddlenlp.transformers import RobertaForSequenceClassification as SeqClfModel\n",
    "from paddlenlp.transformers import RobertaTokenizer as PTMTokenizer\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "MODEL_NAME = \"roberta-wwm-ext\"\n",
    "tokenizer = PTMTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "\n",
    "def example_converter(example, tokenizer, max_seq_length=128):\n",
    "    \n",
    "    text, label = example\n",
    "    encoded_inputs = tokenizer(text=text, max_seq_len=max_seq_length)\n",
    "    input_ids = encoded_inputs[\"input_ids\"]\n",
    "    token_type_ids = encoded_inputs[\"token_type_ids\"]\n",
    "    label = np.array([label], dtype=\"int64\")\n",
    "    return input_ids, token_type_ids, label\n",
    "\n",
    "\n",
    "def get_trans_fn(text_encoder, max_seq_length=128):\n",
    "    return lambda ex: example_converter(ex, text_encoder, max_seq_length)\n",
    "\n",
    "\n",
    "def get_batchify_fn(tokenizer=tokenizer):\n",
    "    \n",
    "    batchify_fn = lambda samples, fn=Tuple(\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id), \n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_type_id),\n",
    "        Stack(dtype=\"int64\")\n",
    "    ): fn(samples)\n",
    "    \n",
    "    return batchify_fn\n",
    "\n",
    "\n",
    "def create_dataloader(dataset, \n",
    "                      trans_fn, \n",
    "                      batchify_fn, \n",
    "                      test=False,\n",
    "                      batch_size=128, \n",
    "                      shuffle=True, \n",
    "                      sampler=BatchSampler):\n",
    "    \n",
    "    if test:\n",
    "        dataset = [[d, 0] for d in dataset]\n",
    "\n",
    "    if not isinstance(dataset, MapDataset):\n",
    "        dataset = MapDataset(dataset)\n",
    "        \n",
    "    dataset.map(trans_fn)\n",
    "    batch_sampler = sampler(dataset, \n",
    "                            shuffle=shuffle, \n",
    "                            batch_size=batch_size)\n",
    "    \n",
    "    dataloder = DataLoader(dataset, \n",
    "                           batch_sampler=batch_sampler, \n",
    "                           collate_fn=batchify_fn)\n",
    "    \n",
    "    return dataloder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-23T20:41:34.984453Z",
     "iopub.status.busy": "2022-03-23T20:41:34.983842Z",
     "iopub.status.idle": "2022-03-23T20:41:36.064153Z",
     "shell.execute_reply": "2022-03-23T20:41:36.063250Z",
     "shell.execute_reply.started": "2022-03-23T20:41:34.984415Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_seq_length = 16; batch_size = 512\n",
    "trans_fn = get_trans_fn(tokenizer, max_seq_length)\n",
    "batchify_fn = get_batchify_fn()\n",
    "train_loader = create_dataloader(train_set, trans_fn, batchify_fn, batch_size=batch_size)\n",
    "dev_loader = create_dataloader(dev_set, trans_fn, batchify_fn, batch_size=batch_size)\n",
    "test_loader = create_dataloader(test_set, trans_fn, batchify_fn, shuffle=False, test=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-23T20:41:36.066164Z",
     "iopub.status.busy": "2022-03-23T20:41:36.065492Z",
     "iopub.status.idle": "2022-03-23T20:41:53.238572Z",
     "shell.execute_reply": "2022-03-23T20:41:53.237694Z",
     "shell.execute_reply.started": "2022-03-23T20:41:36.066132Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-24 04:41:36,073] [    INFO] - Downloading https://paddlenlp.bj.bcebos.com/models/transformers/roberta_base/roberta_chn_base.pdparams and saved to /home/aistudio/.paddlenlp/models/roberta-wwm-ext\n",
      "[2022-03-24 04:41:36,077] [    INFO] - Downloading roberta_chn_base.pdparams from https://paddlenlp.bj.bcebos.com/models/transformers/roberta_base/roberta_chn_base.pdparams\n",
      "100%|██████████| 399505/399505 [00:10<00:00, 39369.04it/s]\n",
      "W0324 04:41:46.315188  4968 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1\n",
      "W0324 04:41:46.320957  4968 device_context.cc:465] device: 0, cuDNN Version: 7.6.\n"
     ]
    }
   ],
   "source": [
    "import paddle \n",
    "from paddlenlp.transformers import LinearDecayWithWarmup\n",
    "\n",
    "\n",
    "model = SeqClfModel.from_pretrained(MODEL_NAME, num_classes=len(idx_to_label))\n",
    "\n",
    "learning_rate = 5e-5; epochs = 1\n",
    "warmup_proportion = 0.1; weight_decay = 0.01\n",
    "num_training_steps = len(train_loader) * epochs\n",
    "lr_scheduler = LinearDecayWithWarmup(learning_rate, num_training_steps, warmup_proportion)\n",
    "optimizer = paddle.optimizer.AdamW(\n",
    "    learning_rate=lr_scheduler,\n",
    "    parameters=model.parameters(),\n",
    "    weight_decay=weight_decay,\n",
    "    apply_decay_param_fun=lambda x: x in [\n",
    "        p.name for n, p in model.named_parameters()\n",
    "        if not any(nd in n for nd in [\"bias\", \"norm\"])\n",
    "    ])\n",
    "\n",
    "criterion = paddle.nn.loss.CrossEntropyLoss()\n",
    "metric = paddle.metric.Accuracy()\n",
    "\n",
    "\n",
    "@paddle.no_grad()\n",
    "def evaluate(model, criterion, metric, data_loader):\n",
    "    \"\"\"\n",
    "    Given a dataset, it evals model and computes the metric.\n",
    "\n",
    "    Args:\n",
    "        model(obj:`paddle.nn.Layer`): A model to classify texts.\n",
    "        data_loader(obj:`paddle.io.DataLoader`): The dataset loader which generates batches.\n",
    "        criterion(obj:`paddle.nn.Layer`): It can compute the loss.\n",
    "        metric(obj:`paddle.metric.Metric`): The evaluation metric.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    metric.reset()\n",
    "    losses = []\n",
    "    for batch in data_loader:\n",
    "        input_ids, token_type_ids, labels = batch\n",
    "        logits = model(input_ids, token_type_ids)\n",
    "        loss = criterion(logits, labels)\n",
    "        losses.append(loss.numpy())\n",
    "        correct = metric.compute(logits, labels)\n",
    "        metric.update(correct)\n",
    "        accu = metric.accumulate()\n",
    "    print(\"eval loss: %.5f, accu: %.5f\" % (np.mean(losses), accu))\n",
    "    model.train()\n",
    "    metric.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-23T20:41:53.240727Z",
     "iopub.status.busy": "2022-03-23T20:41:53.239864Z",
     "iopub.status.idle": "2022-03-23T20:51:09.703900Z",
     "shell.execute_reply": "2022-03-23T20:51:09.702851Z",
     "shell.execute_reply.started": "2022-03-23T20:41:53.240693Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 100, epoch: 1, batch: 100, loss: 0.42963, acc: 0.64842\n",
      "global step 200, epoch: 1, batch: 200, loss: 0.24568, acc: 0.77727\n",
      "global step 300, epoch: 1, batch: 300, loss: 0.25414, acc: 0.82390\n",
      "global step 400, epoch: 1, batch: 400, loss: 0.22092, acc: 0.84855\n",
      "global step 500, epoch: 1, batch: 500, loss: 0.20637, acc: 0.86425\n",
      "global step 600, epoch: 1, batch: 600, loss: 0.20696, acc: 0.87554\n",
      "global step 700, epoch: 1, batch: 700, loss: 0.24308, acc: 0.88389\n",
      "global step 800, epoch: 1, batch: 800, loss: 0.21501, acc: 0.89002\n",
      "global step 900, epoch: 1, batch: 900, loss: 0.20809, acc: 0.89540\n",
      "global step 1000, epoch: 1, batch: 1000, loss: 0.21042, acc: 0.89967\n",
      "global step 1100, epoch: 1, batch: 1100, loss: 0.18128, acc: 0.90324\n",
      "global step 1200, epoch: 1, batch: 1200, loss: 0.18740, acc: 0.90622\n",
      "eval loss: 0.17258, accu: 0.94566\n"
     ]
    }
   ],
   "source": [
    "import paddle.nn.functional as F\n",
    "\n",
    "\n",
    "global_step = 0\n",
    "paddle.set_device(\"gpu\")\n",
    "for epoch in range(1, epochs + 1):\n",
    "    for step, batch in enumerate(train_loader, start=1):\n",
    "        input_ids, segment_ids, labels = batch\n",
    "        logits = model(input_ids, segment_ids)\n",
    "        loss = criterion(logits, labels)\n",
    "        probs = F.softmax(logits, axis=1)\n",
    "        correct = metric.compute(probs, labels)\n",
    "        metric.update(correct)\n",
    "        acc = metric.accumulate()\n",
    "\n",
    "        global_step += 1\n",
    "        if global_step % 100 == 0 :\n",
    "            print(\"global step %d, epoch: %d, batch: %d, loss: %.5f, acc: %.5f\" % (global_step, epoch, step, loss, acc))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.clear_grad()\n",
    "    evaluate(model, criterion, metric, dev_loader)\n",
    "\n",
    "\n",
    "# model.save_pretrained('/home/aistudio/checkpoint')\n",
    "# tokenizer.save_pretrained('/home/aistudio/checkpoint')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-23T20:51:09.705821Z",
     "iopub.status.busy": "2022-03-23T20:51:09.705264Z",
     "iopub.status.idle": "2022-03-23T20:51:44.432500Z",
     "shell.execute_reply": "2022-03-23T20:51:44.431553Z",
     "shell.execute_reply.started": "2022-03-23T20:51:09.705792Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "for batch in test_loader:\n",
    "    input_ids, segment_ids, _ = batch\n",
    "    logits = model(input_ids, segment_ids)\n",
    "    probs = F.softmax(logits, axis=1)\n",
    "    preds = paddle.argmax(probs, axis=1).numpy().tolist()\n",
    "    predictions.extend(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-23T20:51:44.434325Z",
     "iopub.status.busy": "2022-03-23T20:51:44.433840Z",
     "iopub.status.idle": "2022-03-23T20:51:44.463537Z",
     "shell.execute_reply": "2022-03-23T20:51:44.462692Z",
     "shell.execute_reply.started": "2022-03-23T20:51:44.434292Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('result.txt', 'w') as f:\n",
    "    f.write(idx_to_label[predictions[0]])\n",
    "    for p in predictions[1:]:\n",
    "        f.write('\\n' + idx_to_label[p])\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
