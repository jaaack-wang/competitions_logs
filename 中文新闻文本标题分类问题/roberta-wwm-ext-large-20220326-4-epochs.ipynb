{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-27T03:01:43.599713Z",
     "iopub.status.busy": "2022-03-27T03:01:43.599372Z",
     "iopub.status.idle": "2022-03-27T03:01:43.605116Z",
     "shell.execute_reply": "2022-03-27T03:01:43.604454Z",
     "shell.execute_reply.started": "2022-03-27T03:01:43.599680Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_dataset(fpath, test=False, num_row_to_skip=0):\n",
    "    data = open(fpath)\n",
    "    for _ in range(num_row_to_skip):\n",
    "        next(data)\n",
    "\n",
    "    out = []\n",
    "\n",
    "    if test:\n",
    "        for line in data:\n",
    "            out.append(line.strip())\n",
    "        \n",
    "        return out\n",
    "\n",
    "    idx_to_label = {}\n",
    "    for line in data:\n",
    "        line = line.strip().split('\\t')\n",
    "        if len(line) == 3:\n",
    "            idx, label, text = line\n",
    "            idx = int(idx)\n",
    "            idx_to_label[idx] = label\n",
    "            out.append([text, idx])\n",
    "    \n",
    "    return out, idx_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-27T03:01:43.642952Z",
     "iopub.status.busy": "2022-03-27T03:01:43.642581Z",
     "iopub.status.idle": "2022-03-27T03:01:45.420990Z",
     "shell.execute_reply": "2022-03-27T03:01:45.420020Z",
     "shell.execute_reply.started": "2022-03-27T03:01:43.642918Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(752471,\n",
       " [['上证50ETF净申购突增', 0], ['交银施罗德保本基金将发行', 0]],\n",
       " {0: '财经',\n",
       "  1: '彩票',\n",
       "  2: '房产',\n",
       "  3: '股票',\n",
       "  4: '家居',\n",
       "  5: '教育',\n",
       "  6: '科技',\n",
       "  7: '社会',\n",
       "  8: '时尚',\n",
       "  9: '时政',\n",
       "  10: '体育',\n",
       "  11: '星座',\n",
       "  12: '游戏',\n",
       "  13: '娱乐'})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set, idx_to_label = load_dataset('./data/data12701/Train.txt')\n",
    "len(train_set), train_set[:2], idx_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T03:01:45.422659Z",
     "iopub.status.busy": "2022-03-27T03:01:45.422375Z",
     "iopub.status.idle": "2022-03-27T03:01:45.425432Z",
     "shell.execute_reply": "2022-03-27T03:01:45.424842Z",
     "shell.execute_reply.started": "2022-03-27T03:01:45.422634Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # split the train_set into train and dev sets\n",
    "# from random import shuffle, seed\n",
    "\n",
    "# seed(43)\n",
    "# shuffle(train_set)\n",
    "\n",
    "# train_set, dev_set = train_set[:652471], train_set[652471: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-27T03:01:45.426670Z",
     "iopub.status.busy": "2022-03-27T03:01:45.426334Z",
     "iopub.status.idle": "2022-03-27T03:01:45.472395Z",
     "shell.execute_reply": "2022-03-27T03:01:45.471796Z",
     "shell.execute_reply.started": "2022-03-27T03:01:45.426648Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83599, ['北京君太百货璀璨秋色 满100省353020元', '教育部：小学高年级将开始学习性知识'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = load_dataset('./data/data12701/Test.txt', test=True)\n",
    "len(test_set), test_set[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Transform text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-27T03:01:45.473786Z",
     "iopub.status.busy": "2022-03-27T03:01:45.473373Z",
     "iopub.status.idle": "2022-03-27T03:01:47.282965Z",
     "shell.execute_reply": "2022-03-27T03:01:47.282263Z",
     "shell.execute_reply.started": "2022-03-27T03:01:45.473758Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-27 11:01:47,264] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/roberta-wwm-ext-large/vocab.txt\n"
     ]
    }
   ],
   "source": [
    "from paddlenlp.datasets import MapDataset\n",
    "from paddle.io import BatchSampler, DataLoader\n",
    "from paddlenlp.data import Pad, Stack, Tuple\n",
    "from paddlenlp.transformers import RobertaForSequenceClassification as SeqClfModel\n",
    "from paddlenlp.transformers import RobertaTokenizer as PTMTokenizer\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "MODEL_NAME = \"roberta-wwm-ext-large\"\n",
    "tokenizer = PTMTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "\n",
    "def example_converter(example, tokenizer, max_seq_length=128):\n",
    "    \n",
    "    text, label = example\n",
    "    encoded_inputs = tokenizer(text=text, max_seq_len=max_seq_length)\n",
    "    input_ids = encoded_inputs[\"input_ids\"]\n",
    "    token_type_ids = encoded_inputs[\"token_type_ids\"]\n",
    "    label = np.array([label], dtype=\"int64\")\n",
    "    return input_ids, token_type_ids, label\n",
    "\n",
    "\n",
    "def get_trans_fn(text_encoder, max_seq_length=128):\n",
    "    return lambda ex: example_converter(ex, text_encoder, max_seq_length)\n",
    "\n",
    "\n",
    "def get_batchify_fn(tokenizer=tokenizer):\n",
    "    \n",
    "    batchify_fn = lambda samples, fn=Tuple(\n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_id), \n",
    "        Pad(axis=0, pad_val=tokenizer.pad_token_type_id),\n",
    "        Stack(dtype=\"int64\")\n",
    "    ): fn(samples)\n",
    "    \n",
    "    return batchify_fn\n",
    "\n",
    "\n",
    "def create_dataloader(dataset, \n",
    "                      trans_fn, \n",
    "                      batchify_fn, \n",
    "                      test=False,\n",
    "                      batch_size=128, \n",
    "                      shuffle=True, \n",
    "                      sampler=BatchSampler):\n",
    "    \n",
    "    if test:\n",
    "        dataset = [[d, 0] for d in dataset]\n",
    "\n",
    "    if not isinstance(dataset, MapDataset):\n",
    "        dataset = MapDataset(dataset)\n",
    "        \n",
    "    dataset.map(trans_fn)\n",
    "    batch_sampler = sampler(dataset, \n",
    "                            shuffle=shuffle, \n",
    "                            batch_size=batch_size)\n",
    "    \n",
    "    dataloder = DataLoader(dataset, \n",
    "                           batch_sampler=batch_sampler, \n",
    "                           collate_fn=batchify_fn)\n",
    "    \n",
    "    return dataloder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-03-27T03:01:47.285340Z",
     "iopub.status.busy": "2022-03-27T03:01:47.284866Z",
     "iopub.status.idle": "2022-03-27T03:01:47.630468Z",
     "shell.execute_reply": "2022-03-27T03:01:47.629747Z",
     "shell.execute_reply.started": "2022-03-27T03:01:47.285308Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_seq_length = 40; batch_size = 200\n",
    "trans_fn = get_trans_fn(tokenizer, max_seq_length)\n",
    "batchify_fn = get_batchify_fn()\n",
    "train_loader = create_dataloader(train_set, trans_fn, batchify_fn, batch_size=batch_size)\n",
    "# dev_loader = create_dataloader(dev_set, trans_fn, batchify_fn, batch_size=batch_size)\n",
    "test_loader = create_dataloader(test_set, trans_fn, batchify_fn, shuffle=False, test=True, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T03:01:47.632496Z",
     "iopub.status.busy": "2022-03-27T03:01:47.632050Z",
     "iopub.status.idle": "2022-03-27T03:01:57.989315Z",
     "shell.execute_reply": "2022-03-27T03:01:57.988521Z",
     "shell.execute_reply.started": "2022-03-27T03:01:47.632451Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-27 11:01:47,638] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/roberta-wwm-ext-large/roberta_chn_large.pdparams\n",
      "W0327 11:01:47.642578   379 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1\n",
      "W0327 11:01:47.648586   379 device_context.cc:465] device: 0, cuDNN Version: 7.6.\n"
     ]
    }
   ],
   "source": [
    "import paddle \n",
    "from paddlenlp.transformers import LinearDecayWithWarmup\n",
    "\n",
    "\n",
    "model = SeqClfModel.from_pretrained(MODEL_NAME, num_classes=len(idx_to_label))\n",
    "\n",
    "learning_rate = 4e-5; epochs = 3\n",
    "warmup_proportion = 0.0; weight_decay = 0.001\n",
    "num_training_steps = len(train_loader) * epochs\n",
    "lr_scheduler = LinearDecayWithWarmup(learning_rate, num_training_steps, warmup_proportion)\n",
    "optimizer = paddle.optimizer.AdamW(\n",
    "    learning_rate=lr_scheduler,\n",
    "    parameters=model.parameters(),\n",
    "    weight_decay=weight_decay,\n",
    "    apply_decay_param_fun=lambda x: x in [\n",
    "        p.name for n, p in model.named_parameters()\n",
    "        if not any(nd in n for nd in [\"bias\", \"norm\"])\n",
    "    ])\n",
    "\n",
    "criterion = paddle.nn.loss.CrossEntropyLoss()\n",
    "metric = paddle.metric.Accuracy()\n",
    "\n",
    "\n",
    "# @paddle.no_grad()\n",
    "# def evaluate(model, criterion, metric, data_loader):\n",
    "#     \"\"\"\n",
    "#     Given a dataset, it evals model and computes the metric.\n",
    "\n",
    "#     Args:\n",
    "#         model(obj:`paddle.nn.Layer`): A model to classify texts.\n",
    "#         data_loader(obj:`paddle.io.DataLoader`): The dataset loader which generates batches.\n",
    "#         criterion(obj:`paddle.nn.Layer`): It can compute the loss.\n",
    "#         metric(obj:`paddle.metric.Metric`): The evaluation metric.\n",
    "#     \"\"\"\n",
    "#     model.eval()\n",
    "#     metric.reset()\n",
    "#     losses = []\n",
    "#     for batch in data_loader:\n",
    "#         input_ids, token_type_ids, labels = batch\n",
    "#         logits = model(input_ids, token_type_ids)\n",
    "#         loss = criterion(logits, labels)\n",
    "#         losses.append(loss.numpy())\n",
    "#         correct = metric.compute(logits, labels)\n",
    "#         metric.update(correct)\n",
    "#         accu = metric.accumulate()\n",
    "#     print(\"eval loss: %.5f, accu: %.5f\" % (np.mean(losses), accu))\n",
    "#     model.train()\n",
    "#     metric.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T03:01:57.990960Z",
     "iopub.status.busy": "2022-03-27T03:01:57.990381Z",
     "iopub.status.idle": "2022-03-27T03:01:57.994093Z",
     "shell.execute_reply": "2022-03-27T03:01:57.993524Z",
     "shell.execute_reply.started": "2022-03-27T03:01:57.990931Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import paddle.nn.functional as F\n",
    "\n",
    "\n",
    "def run():\n",
    "    global_step = 0\n",
    "    paddle.set_device(\"gpu\")\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        for step, batch in enumerate(train_loader, start=1):\n",
    "            input_ids, segment_ids, labels = batch\n",
    "            logits = model(input_ids, segment_ids)\n",
    "            loss = criterion(logits, labels)\n",
    "            probs = F.softmax(logits, axis=1)\n",
    "            correct = metric.compute(probs, labels)\n",
    "            metric.update(correct)\n",
    "            acc = metric.accumulate()\n",
    "\n",
    "            global_step += 1\n",
    "            if global_step % 500 == 0 :\n",
    "                print(\"global step %d, epoch: %d, batch: %d, loss: %.5f, acc: %.5f\" % (global_step, epoch, step, loss, acc))\n",
    "        \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.clear_grad()\n",
    "        # evaluate(model, criterion, metric, dev_loader)\n",
    "\n",
    "\n",
    "run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-27T03:02:01.076942Z",
     "iopub.status.busy": "2022-03-27T03:02:01.076477Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = open('result.txt', 'w')\n",
    "\n",
    "for batch in test_loader:\n",
    "    input_ids, segment_ids, _ = batch\n",
    "    logits = model(input_ids, segment_ids)\n",
    "    probs = F.softmax(logits, axis=1)\n",
    "    preds = paddle.argmax(probs, axis=1).numpy().tolist()\n",
    "    for p in preds:\n",
    "        f.write('\\n' + idx_to_label[p])\n",
    "\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
