{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T16:00:42.478371Z",
     "iopub.status.busy": "2022-03-25T16:00:42.478094Z",
     "iopub.status.idle": "2022-03-25T16:00:42.481204Z",
     "shell.execute_reply": "2022-03-25T16:00:42.480682Z",
     "shell.execute_reply.started": "2022-03-25T16:00:42.478344Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !unzip /home/aistudio/data/data78992/lcqmc.zip -d /home/aistudio/data/\n",
    "# !unzip /home/aistudio/data/data78992/paws-x-zh.zip -d /home/aistudio/data/\n",
    "# !unzip /home/aistudio/data/data78992/bq_corpus.zip -d /home/aistudio/data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T16:00:42.482644Z",
     "iopub.status.busy": "2022-03-25T16:00:42.482424Z",
     "iopub.status.idle": "2022-03-25T16:00:42.488545Z",
     "shell.execute_reply": "2022-03-25T16:00:42.488023Z",
     "shell.execute_reply.started": "2022-03-25T16:00:42.482620Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_dataset(fpath, num_row_skip=0):\n",
    "\n",
    "    def read(fp):\n",
    "        data = open(fp)\n",
    "\n",
    "        for _ in range(num_row_skip):\n",
    "            next(data)\n",
    "\n",
    "        if \"test\" in fp:\n",
    "            for line in data:\n",
    "                line = line.strip().split('\\t')\n",
    "                yield line[0], line[1]\n",
    "        else:\n",
    "            for line in data:\n",
    "                line = line.strip().split('\\t')\n",
    "                if len(line) == 3:\n",
    "                    yield line[0], line[1], int(line[2])\n",
    "\n",
    "    if isinstance(fpath, str):\n",
    "        return list(read(fpath))\n",
    "    elif isinstance(fpath, (list, tuple)):\n",
    "        return [list(read(fp)) for fp in fpath]\n",
    "    else:\n",
    "        raise TypeError(\"Input fpath must be a str or a list/tuple of str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T16:00:42.489709Z",
     "iopub.status.busy": "2022-03-25T16:00:42.489450Z",
     "iopub.status.idle": "2022-03-25T16:00:42.627083Z",
     "shell.execute_reply": "2022-03-25T16:00:42.626419Z",
     "shell.execute_reply.started": "2022-03-25T16:00:42.489687Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_set, dev_set, test_set = load_dataset(['./data/paws-x-zh/train.tsv', './data/paws-x-zh/dev.tsv', './data/paws-x-zh/test.tsv'])\n",
    "# len(train_set), len(dev_set), len(test_set)\n",
    "train_set = train_set + dev_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Transform text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T16:00:42.628504Z",
     "iopub.status.busy": "2022-03-25T16:00:42.628064Z",
     "iopub.status.idle": "2022-03-25T16:00:55.365835Z",
     "shell.execute_reply": "2022-03-25T16:00:55.365113Z",
     "shell.execute_reply.started": "2022-03-25T16:00:42.628477Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-26 00:00:44,401] [    INFO] - Loading token embedding...\n",
      "W0326 00:00:49.819521  2389 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1\n",
      "W0326 00:00:49.824138  2389 device_context.cc:465] device: 0, cuDNN Version: 7.6.\n",
      "[2022-03-26 00:00:55,279] [    INFO] - Finish loading embedding vector.\n",
      "[2022-03-26 00:00:55,282] [    INFO] - Token Embedding info:             \n",
      "Unknown index: 635963             \n",
      "Unknown token: [UNK]             \n",
      "Padding index: 635964             \n",
      "Padding token: [PAD]             \n",
      "Shape :[635965, 300]\n"
     ]
    }
   ],
   "source": [
    "from paddlenlp.datasets import MapDataset\n",
    "from paddle.io import BatchSampler, DataLoader\n",
    "from paddlenlp.data import Pad, Stack, Tuple\n",
    "from paddlenlp.embeddings import TokenEmbedding\n",
    "import jieba\n",
    "\n",
    "\n",
    "name = \"w2v.baidu_encyclopedia.target.word-word.dim300\"\n",
    "token_embedding = TokenEmbedding(embedding_name=name)\n",
    "vocab = token_embedding.vocab \n",
    "\n",
    "\n",
    "def text_encoder(text):\n",
    "    tks = jieba.lcut(text)\n",
    "    return [vocab[tk] for tk in tks]\n",
    "\n",
    "\n",
    "def example_converter(example, text_encoder):\n",
    "    text_a, text_b, label = example\n",
    "    text_a_ids = text_encoder(text_a)\n",
    "    text_b_ids = text_encoder(text_b)\n",
    "    return text_a_ids, text_b_ids, label\n",
    "\n",
    "\n",
    "def get_trans_fn(text_encoder=text_encoder):\n",
    "    return lambda ex: example_converter(ex, text_encoder)\n",
    "\n",
    "\n",
    "batchify_fn = lambda samples, fn=Tuple(\n",
    "    Pad(axis=0, pad_val=vocab['[PAD]']), \n",
    "    Pad(axis=0, pad_val=vocab['[PAD]']),\n",
    "    Stack(dtype=\"int64\")\n",
    "    ): fn(samples)\n",
    "\n",
    "\n",
    "def create_dataloader(dataset, \n",
    "                      trans_fn, \n",
    "                      batchify_fn, \n",
    "                      test=False,\n",
    "                      batch_size=128, \n",
    "                      shuffle=True, \n",
    "                      sampler=BatchSampler):\n",
    "    \n",
    "    if test:\n",
    "        dataset = [d + (0,) for d in dataset]\n",
    "\n",
    "    if not isinstance(dataset, MapDataset):\n",
    "        dataset = MapDataset(dataset)\n",
    "        \n",
    "    dataset.map(trans_fn)\n",
    "    batch_sampler = sampler(dataset, \n",
    "                            shuffle=shuffle, \n",
    "                            batch_size=batch_size)\n",
    "    \n",
    "    dataloder = DataLoader(dataset, \n",
    "                           batch_sampler=batch_sampler, \n",
    "                           collate_fn=batchify_fn)\n",
    "    \n",
    "    return dataloder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T16:00:55.367473Z",
     "iopub.status.busy": "2022-03-25T16:00:55.367003Z",
     "iopub.status.idle": "2022-03-25T16:00:55.406916Z",
     "shell.execute_reply": "2022-03-25T16:00:55.405832Z",
     "shell.execute_reply.started": "2022-03-25T16:00:55.367445Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "trans_fn = get_trans_fn()\n",
    "train_loader = create_dataloader(train_set, trans_fn, batchify_fn, batch_size=batch_size)\n",
    "# dev_loader = create_dataloader(dev_set, trans_fn, batchify_fn, batch_size=batch_size)\n",
    "test_loader = create_dataloader(test_set, trans_fn, batchify_fn, shuffle=False, test=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T16:00:55.408256Z",
     "iopub.status.busy": "2022-03-25T16:00:55.408082Z",
     "iopub.status.idle": "2022-03-25T16:00:55.419807Z",
     "shell.execute_reply": "2022-03-25T16:00:55.418473Z",
     "shell.execute_reply.started": "2022-03-25T16:00:55.408233Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import paddle \n",
    "import paddle.nn as nn\n",
    "import paddle.nn.functional as F\n",
    "\n",
    "\n",
    "class CNN(nn.Layer):\n",
    "\n",
    "    def __init__(self, \n",
    "                 embedding,\n",
    "                 output_dim,\n",
    "                 embedding_dim,\n",
    "                 padding_idx=vocab['[PAD]'],\n",
    "                 num_filter=256,\n",
    "                 filter_sizes=(3,),\n",
    "                 activation=nn.ReLU()):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = embedding\n",
    "        \n",
    "        self.convs = nn.LayerList([\n",
    "            nn.Conv1D(\n",
    "                in_channels=embedding_dim,\n",
    "                out_channels=num_filter,\n",
    "                kernel_size=fz\n",
    "            ) for fz in filter_sizes\n",
    "        ])\n",
    "        self.fc1 = nn.Linear(len(filter_sizes) * num_filter * 4, \n",
    "                            len(filter_sizes) * num_filter)\n",
    "        self.activation = activation\n",
    "        self.fc2 = nn.Linear(len(filter_sizes) * num_filter, \n",
    "                            len(filter_sizes) * num_filter // 2)\n",
    "        self.fc3 = nn.Linear(len(filter_sizes) * num_filter // 2, \n",
    "                            len(filter_sizes) * num_filter // 4)\n",
    "        self.fc4 = nn.Linear(len(filter_sizes) * num_filter // 4, output_dim)\n",
    "    \n",
    "    def encoder(self, embd):\n",
    "        embd = embd.transpose((0,2,1))\n",
    "        conved = [self.activation(conv(embd)) for conv in self.convs]\n",
    "        max_pooled = [F.adaptive_max_pool1d(conv, output_size=1).squeeze(2) for conv in conved]\n",
    "        pooled_concat = paddle.concat(max_pooled, axis=1)\n",
    "        return pooled_concat\n",
    " \n",
    "    def forward(self, text_a_ids, text_b_ids):\n",
    "        text_a_ids_embd = self.embedding(text_a_ids)\n",
    "        text_b_ids_embd = self.embedding(text_b_ids)\n",
    "\n",
    "        encoded_a = self.encoder(text_a_ids_embd)\n",
    "        encoded_b = self.encoder(text_b_ids_embd)\n",
    "        dif = encoded_a - encoded_b\n",
    "        mul = encoded_a * encoded_b\n",
    "\n",
    "        concat = paddle.concat([encoded_a, encoded_b, dif, mul], axis=-1)\n",
    "        hidden = self.activation(self.fc1(concat))\n",
    "        hidden = self.activation(self.fc2(hidden))\n",
    "        hidden = self.activation(self.fc3(hidden))\n",
    "        logits = self.fc4(hidden)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T16:09:43.492291Z",
     "iopub.status.busy": "2022-03-25T16:09:43.491791Z",
     "iopub.status.idle": "2022-03-25T16:09:43.499126Z",
     "shell.execute_reply": "2022-03-25T16:09:43.498240Z",
     "shell.execute_reply.started": "2022-03-25T16:09:43.492252Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from paddlenlp.transformers import LinearDecayWithWarmup\n",
    "\n",
    "epoch = 20\n",
    "weight_decay = 0.001\n",
    "warmup_proportion = 0.0\n",
    "lr_scheduler = LinearDecayWithWarmup(5e-4, len(train_loader) * epoch,\n",
    "                                         warmup_proportion)\n",
    "\n",
    "def get_model(model):\n",
    "    decay_params = [\n",
    "        p.name for n, p in model.named_parameters()\n",
    "        if not any(nd in n for nd in [\"bias\", \"norm\"])\n",
    "    ]\n",
    "    optimizer = paddle.optimizer.AdamW(\n",
    "    parameters=model.parameters(), \n",
    "    learning_rate=lr_scheduler, \n",
    "    weight_decay=weight_decay, \n",
    "    apply_decay_param_fun=lambda x: x in decay_params)\n",
    "\n",
    "    criterion = paddle.nn.CrossEntropyLoss()\n",
    "\n",
    "    model = paddle.Model(model)\n",
    "    metric = paddle.metric.Accuracy()\n",
    "    model.prepare(optimizer, criterion, metric)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T16:09:45.143149Z",
     "iopub.status.busy": "2022-03-25T16:09:45.142655Z",
     "iopub.status.idle": "2022-03-25T16:09:45.152236Z",
     "shell.execute_reply": "2022-03-25T16:09:45.151624Z",
     "shell.execute_reply.started": "2022-03-25T16:09:45.143111Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = CNN(token_embedding, 2, 300)\n",
    "model = get_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T16:09:46.746531Z",
     "iopub.status.busy": "2022-03-25T16:09:46.746073Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous steps.\n",
      "Epoch 1/20\n",
      "step 100/799 - loss: 0.6855 - acc: 0.5355 - 43ms/step\n",
      "step 200/799 - loss: 0.6819 - acc: 0.5444 - 43ms/step\n",
      "step 300/799 - loss: 0.6815 - acc: 0.5472 - 43ms/step\n",
      "step 400/799 - loss: 0.6595 - acc: 0.5477 - 43ms/step\n",
      "step 500/799 - loss: 0.6932 - acc: 0.5530 - 43ms/step\n",
      "step 600/799 - loss: 0.6689 - acc: 0.5589 - 43ms/step\n",
      "step 700/799 - loss: 0.6306 - acc: 0.5615 - 43ms/step\n",
      "step 799/799 - loss: 0.6883 - acc: 0.5632 - 43ms/step\n",
      "Epoch 2/20\n",
      "step 100/799 - loss: 0.6881 - acc: 0.6127 - 43ms/step\n",
      "step 200/799 - loss: 0.6318 - acc: 0.6113 - 43ms/step\n",
      "step 300/799 - loss: 0.5764 - acc: 0.6099 - 43ms/step\n",
      "step 400/799 - loss: 0.6433 - acc: 0.6095 - 43ms/step\n",
      "step 500/799 - loss: 0.6036 - acc: 0.6088 - 43ms/step\n",
      "step 600/799 - loss: 0.6195 - acc: 0.6107 - 43ms/step\n",
      "step 700/799 - loss: 0.6686 - acc: 0.6104 - 43ms/step\n",
      "step 799/799 - loss: 0.6211 - acc: 0.6119 - 43ms/step\n",
      "Epoch 3/20\n",
      "step 100/799 - loss: 0.5265 - acc: 0.7159 - 45ms/step\n",
      "step 200/799 - loss: 0.4832 - acc: 0.7166 - 44ms/step\n",
      "step 300/799 - loss: 0.5575 - acc: 0.7139 - 44ms/step\n",
      "step 400/799 - loss: 0.5709 - acc: 0.7073 - 43ms/step\n",
      "step 500/799 - loss: 0.5589 - acc: 0.7070 - 43ms/step\n",
      "step 600/799 - loss: 0.5180 - acc: 0.7055 - 43ms/step\n",
      "step 700/799 - loss: 0.4546 - acc: 0.7056 - 43ms/step\n",
      "step 799/799 - loss: 0.6156 - acc: 0.7060 - 43ms/step\n",
      "Epoch 4/20\n",
      "step 100/799 - loss: 0.2846 - acc: 0.8341 - 46ms/step\n",
      "step 200/799 - loss: 0.4105 - acc: 0.8339 - 45ms/step\n",
      "step 300/799 - loss: 0.3825 - acc: 0.8257 - 45ms/step\n",
      "step 400/799 - loss: 0.3166 - acc: 0.8221 - 44ms/step\n",
      "step 500/799 - loss: 0.4939 - acc: 0.8196 - 44ms/step\n",
      "step 600/799 - loss: 0.5137 - acc: 0.8172 - 44ms/step\n",
      "step 700/799 - loss: 0.4133 - acc: 0.8149 - 44ms/step\n",
      "step 799/799 - loss: 0.3348 - acc: 0.8148 - 43ms/step\n",
      "Epoch 5/20\n",
      "step 100/799 - loss: 0.2441 - acc: 0.9023 - 45ms/step\n",
      "step 200/799 - loss: 0.1439 - acc: 0.8992 - 44ms/step\n",
      "step 300/799 - loss: 0.1906 - acc: 0.8980 - 44ms/step\n",
      "step 400/799 - loss: 0.4003 - acc: 0.8948 - 43ms/step\n",
      "step 500/799 - loss: 0.2526 - acc: 0.8920 - 43ms/step\n",
      "step 600/799 - loss: 0.3177 - acc: 0.8898 - 43ms/step\n",
      "step 700/799 - loss: 0.3024 - acc: 0.8890 - 43ms/step\n",
      "step 799/799 - loss: 0.3643 - acc: 0.8879 - 43ms/step\n",
      "Epoch 6/20\n",
      "step 100/799 - loss: 0.1857 - acc: 0.9397 - 44ms/step\n",
      "step 200/799 - loss: 0.1954 - acc: 0.9387 - 43ms/step\n",
      "step 300/799 - loss: 0.2680 - acc: 0.9360 - 43ms/step\n",
      "step 400/799 - loss: 0.1169 - acc: 0.9352 - 43ms/step\n",
      "step 500/799 - loss: 0.2636 - acc: 0.9340 - 42ms/step\n",
      "step 600/799 - loss: 0.2037 - acc: 0.9335 - 42ms/step\n",
      "step 700/799 - loss: 0.1265 - acc: 0.9321 - 42ms/step\n",
      "step 799/799 - loss: 0.1631 - acc: 0.9310 - 42ms/step\n",
      "Epoch 7/20\n",
      "step 100/799 - loss: 0.1350 - acc: 0.9631 - 43ms/step\n",
      "step 200/799 - loss: 0.1223 - acc: 0.9602 - 43ms/step\n",
      "step 300/799 - loss: 0.1554 - acc: 0.9573 - 43ms/step\n",
      "step 400/799 - loss: 0.0705 - acc: 0.9571 - 43ms/step\n",
      "step 500/799 - loss: 0.1068 - acc: 0.9558 - 43ms/step\n",
      "step 600/799 - loss: 0.0689 - acc: 0.9546 - 43ms/step\n",
      "step 700/799 - loss: 0.2267 - acc: 0.9540 - 43ms/step\n",
      "step 799/799 - loss: 0.1651 - acc: 0.9531 - 42ms/step\n",
      "Epoch 8/20\n",
      "step 100/799 - loss: 0.0924 - acc: 0.9688 - 44ms/step\n",
      "step 200/799 - loss: 0.0398 - acc: 0.9670 - 43ms/step\n",
      "step 300/799 - loss: 0.0223 - acc: 0.9667 - 43ms/step\n",
      "step 400/799 - loss: 0.1437 - acc: 0.9665 - 43ms/step\n",
      "step 500/799 - loss: 0.0745 - acc: 0.9668 - 43ms/step\n",
      "step 600/799 - loss: 0.1972 - acc: 0.9658 - 43ms/step\n",
      "step 700/799 - loss: 0.1324 - acc: 0.9649 - 43ms/step\n",
      "step 799/799 - loss: 0.0796 - acc: 0.9643 - 43ms/step\n",
      "Epoch 9/20\n",
      "step 100/799 - loss: 0.1145 - acc: 0.9747 - 43ms/step\n",
      "step 200/799 - loss: 0.1661 - acc: 0.9729 - 43ms/step\n",
      "step 300/799 - loss: 0.0666 - acc: 0.9713 - 43ms/step\n",
      "step 400/799 - loss: 0.0569 - acc: 0.9711 - 43ms/step\n",
      "step 500/799 - loss: 0.0345 - acc: 0.9706 - 43ms/step\n",
      "step 600/799 - loss: 0.0692 - acc: 0.9700 - 43ms/step\n",
      "step 700/799 - loss: 0.0506 - acc: 0.9695 - 43ms/step\n",
      "step 799/799 - loss: 0.0203 - acc: 0.9692 - 43ms/step\n",
      "Epoch 10/20\n",
      "step 100/799 - loss: 0.0103 - acc: 0.9777 - 43ms/step\n",
      "step 200/799 - loss: 0.0202 - acc: 0.9787 - 43ms/step\n",
      "step 300/799 - loss: 0.0317 - acc: 0.9771 - 43ms/step\n",
      "step 400/799 - loss: 0.0238 - acc: 0.9771 - 42ms/step\n",
      "step 500/799 - loss: 0.0217 - acc: 0.9774 - 42ms/step\n",
      "step 600/799 - loss: 0.0440 - acc: 0.9772 - 42ms/step\n",
      "step 700/799 - loss: 0.0377 - acc: 0.9767 - 42ms/step\n",
      "step 799/799 - loss: 0.0564 - acc: 0.9761 - 42ms/step\n",
      "Epoch 11/20\n",
      "step 100/799 - loss: 0.0324 - acc: 0.9817 - 43ms/step\n",
      "step 200/799 - loss: 0.0469 - acc: 0.9819 - 43ms/step\n",
      "step 300/799 - loss: 0.0709 - acc: 0.9806 - 43ms/step\n",
      "step 400/799 - loss: 0.0205 - acc: 0.9800 - 43ms/step\n",
      "step 500/799 - loss: 0.0218 - acc: 0.9796 - 43ms/step\n",
      "step 600/799 - loss: 0.1889 - acc: 0.9794 - 43ms/step\n",
      "step 700/799 - loss: 0.0264 - acc: 0.9790 - 43ms/step\n",
      "step 799/799 - loss: 0.0165 - acc: 0.9786 - 42ms/step\n",
      "Epoch 12/20\n",
      "step 100/799 - loss: 0.0136 - acc: 0.9884 - 43ms/step\n",
      "step 200/799 - loss: 0.0187 - acc: 0.9855 - 43ms/step\n",
      "step 300/799 - loss: 0.0305 - acc: 0.9838 - 43ms/step\n",
      "step 400/799 - loss: 0.0266 - acc: 0.9830 - 43ms/step\n",
      "step 500/799 - loss: 0.0235 - acc: 0.9826 - 43ms/step\n",
      "step 600/799 - loss: 0.0452 - acc: 0.9816 - 43ms/step\n",
      "step 700/799 - loss: 0.0360 - acc: 0.9814 - 43ms/step\n",
      "step 799/799 - loss: 0.0309 - acc: 0.9808 - 43ms/step\n",
      "Epoch 13/20\n",
      "step 100/799 - loss: 0.0395 - acc: 0.9870 - 45ms/step\n",
      "step 200/799 - loss: 0.0242 - acc: 0.9875 - 44ms/step\n",
      "step 300/799 - loss: 0.0108 - acc: 0.9872 - 44ms/step\n",
      "step 400/799 - loss: 0.0115 - acc: 0.9861 - 43ms/step\n",
      "step 500/799 - loss: 0.0307 - acc: 0.9853 - 43ms/step\n",
      "step 600/799 - loss: 0.0427 - acc: 0.9848 - 44ms/step\n",
      "step 700/799 - loss: 0.0038 - acc: 0.9842 - 43ms/step\n",
      "step 799/799 - loss: 0.0545 - acc: 0.9843 - 43ms/step\n",
      "Epoch 14/20\n",
      "step 100/799 - loss: 6.7606e-04 - acc: 0.9881 - 43ms/step\n",
      "step 200/799 - loss: 0.0107 - acc: 0.9878 - 43ms/step\n",
      "step 300/799 - loss: 0.0120 - acc: 0.9872 - 43ms/step\n",
      "step 400/799 - loss: 0.0660 - acc: 0.9864 - 43ms/step\n",
      "step 500/799 - loss: 0.0186 - acc: 0.9856 - 43ms/step\n",
      "step 600/799 - loss: 0.0143 - acc: 0.9853 - 43ms/step\n",
      "step 700/799 - loss: 0.0311 - acc: 0.9856 - 43ms/step\n",
      "step 799/799 - loss: 0.0176 - acc: 0.9852 - 43ms/step\n",
      "Epoch 15/20\n",
      "step 100/799 - loss: 0.0061 - acc: 0.9872 - 43ms/step\n",
      "step 200/799 - loss: 0.0071 - acc: 0.9870 - 43ms/step\n",
      "step 300/799 - loss: 0.0018 - acc: 0.9873 - 43ms/step\n",
      "step 400/799 - loss: 0.0113 - acc: 0.9870 - 42ms/step\n",
      "step 500/799 - loss: 0.0203 - acc: 0.9869 - 42ms/step\n",
      "step 600/799 - loss: 0.0266 - acc: 0.9868 - 42ms/step\n",
      "step 700/799 - loss: 0.0148 - acc: 0.9869 - 43ms/step\n",
      "step 799/799 - loss: 0.0048 - acc: 0.9867 - 43ms/step\n",
      "Epoch 16/20\n",
      "step 100/799 - loss: 0.0187 - acc: 0.9909 - 45ms/step\n",
      "step 200/799 - loss: 0.0298 - acc: 0.9889 - 43ms/step\n",
      "step 300/799 - loss: 1.6627e-04 - acc: 0.9884 - 43ms/step\n",
      "step 400/799 - loss: 0.0186 - acc: 0.9886 - 43ms/step\n",
      "step 500/799 - loss: 0.0148 - acc: 0.9885 - 43ms/step\n",
      "step 600/799 - loss: 0.0139 - acc: 0.9883 - 43ms/step\n",
      "step 700/799 - loss: 0.0516 - acc: 0.9882 - 43ms/step\n",
      "step 799/799 - loss: 0.0109 - acc: 0.9881 - 43ms/step\n",
      "Epoch 17/20\n",
      "step 100/799 - loss: 0.0090 - acc: 0.9900 - 43ms/step\n",
      "step 200/799 - loss: 0.0283 - acc: 0.9892 - 43ms/step\n",
      "step 300/799 - loss: 0.0096 - acc: 0.9890 - 43ms/step\n",
      "step 400/799 - loss: 2.2236e-04 - acc: 0.9895 - 43ms/step\n",
      "step 500/799 - loss: 0.0128 - acc: 0.9888 - 43ms/step\n",
      "step 600/799 - loss: 0.0154 - acc: 0.9887 - 43ms/step\n",
      "step 700/799 - loss: 0.0107 - acc: 0.9885 - 43ms/step\n",
      "step 799/799 - loss: 0.0356 - acc: 0.9886 - 42ms/step\n",
      "Epoch 18/20\n",
      "step 100/799 - loss: 0.0122 - acc: 0.9900 - 44ms/step\n",
      "step 200/799 - loss: 0.0108 - acc: 0.9902 - 43ms/step\n",
      "step 300/799 - loss: 0.0200 - acc: 0.9905 - 43ms/step\n",
      "step 400/799 - loss: 0.0412 - acc: 0.9904 - 43ms/step\n",
      "step 500/799 - loss: 0.0279 - acc: 0.9901 - 42ms/step\n",
      "step 600/799 - loss: 1.2344e-04 - acc: 0.9897 - 42ms/step\n",
      "step 700/799 - loss: 0.0047 - acc: 0.9896 - 43ms/step\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_loader, epochs=epoch, verbose=2, log_freq=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T16:06:38.051551Z",
     "iopub.status.busy": "2022-03-25T16:06:38.050958Z",
     "iopub.status.idle": "2022-03-25T16:06:39.025082Z",
     "shell.execute_reply": "2022-03-25T16:06:39.024274Z",
     "shell.execute_reply.started": "2022-03-25T16:06:38.051522Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict begin...\n",
      "step 32/32 [==============================] - ETA: 2s - 86ms/ste - ETA: 1s - 57ms/ste - ETA: 1s - 48ms/ste - ETA: 1s - 44ms/ste - ETA: 0s - 41ms/ste - ETA: 0s - 39ms/ste - ETA: 0s - 38ms/ste - ETA: 0s - 37ms/ste - ETA: 0s - 36ms/ste - ETA: 0s - 36ms/ste - ETA: 0s - 35ms/ste - ETA: 0s - 35ms/ste - ETA: 0s - 35ms/ste - ETA: 0s - 34ms/ste - ETA: 0s - 32ms/ste - 30ms/step          \n",
      "Predict samples: 2000\n"
     ]
    }
   ],
   "source": [
    "import paddle.nn.functional as F\n",
    "\n",
    "\n",
    "predictions = []\n",
    "logits = model.predict(test_loader)\n",
    "\n",
    "for batch in logits[0]:\n",
    "    batch = paddle.to_tensor(batch)\n",
    "    probs = F.softmax(batch, axis=1)\n",
    "    preds = paddle.argmax(probs, axis=1).numpy().tolist()\n",
    "    predictions.extend(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T16:06:39.027377Z",
     "iopub.status.busy": "2022-03-25T16:06:39.026561Z",
     "iopub.status.idle": "2022-03-25T16:06:39.034045Z",
     "shell.execute_reply": "2022-03-25T16:06:39.033288Z",
     "shell.execute_reply.started": "2022-03-25T16:06:39.027326Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('paws-x.tsv', 'w') as f:\n",
    "    f.write(\"index\\tprediction\")\n",
    "    for idx, p in enumerate(predictions):\n",
    "        f.write(f\"\\n{idx}\\t{p}\")\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
