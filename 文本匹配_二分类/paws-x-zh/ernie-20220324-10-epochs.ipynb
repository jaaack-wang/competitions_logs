{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T00:23:29.762197Z",
     "iopub.status.busy": "2022-03-25T00:23:29.761835Z",
     "iopub.status.idle": "2022-03-25T00:23:29.764899Z",
     "shell.execute_reply": "2022-03-25T00:23:29.764289Z",
     "shell.execute_reply.started": "2022-03-25T00:23:29.762160Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !unzip /home/aistudio/data/data78992/lcqmc.zip -d /home/aistudio/data/\n",
    "# !unzip /home/aistudio/data/data78992/paws-x-zh.zip -d /home/aistudio/data/\n",
    "# !unzip /home/aistudio/data/data78992/bq_corpus.zip -d /home/aistudio/data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T00:23:29.766299Z",
     "iopub.status.busy": "2022-03-25T00:23:29.766025Z",
     "iopub.status.idle": "2022-03-25T00:23:29.771974Z",
     "shell.execute_reply": "2022-03-25T00:23:29.771365Z",
     "shell.execute_reply.started": "2022-03-25T00:23:29.766277Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_dataset(fpath, num_row_skip=0):\n",
    "\n",
    "    def read(fp):\n",
    "        data = open(fp)\n",
    "\n",
    "        for _ in range(num_row_skip):\n",
    "            next(data)\n",
    "\n",
    "        if \"test\" in fp:\n",
    "            for line in data:\n",
    "                line = line.strip().split('\\t')\n",
    "                yield line[0], line[1]\n",
    "        else:\n",
    "            for line in data:\n",
    "                line = line.strip().split('\\t')\n",
    "                if len(line) == 3:\n",
    "                    yield line[0], line[1], int(line[2])\n",
    "\n",
    "    if isinstance(fpath, str):\n",
    "        return list(read(fpath))\n",
    "    elif isinstance(fpath, (list, tuple)):\n",
    "        return [list(read(fp)) for fp in fpath]\n",
    "    else:\n",
    "        raise TypeError(\"Input fpath must be a str or a list/tuple of str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T00:23:29.772857Z",
     "iopub.status.busy": "2022-03-25T00:23:29.772699Z",
     "iopub.status.idle": "2022-03-25T00:23:29.929742Z",
     "shell.execute_reply": "2022-03-25T00:23:29.929052Z",
     "shell.execute_reply.started": "2022-03-25T00:23:29.772838Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_set, dev_set, test_set = load_dataset(['./data/paws-x-zh/train.tsv', './data/paws-x-zh/dev.tsv', './data/paws-x-zh/test.tsv'])\n",
    "# len(train_set), len(dev_set), len(test_set)\n",
    "train_set = train_set + dev_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Transform text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T00:23:29.931819Z",
     "iopub.status.busy": "2022-03-25T00:23:29.931259Z",
     "iopub.status.idle": "2022-03-25T00:23:31.777100Z",
     "shell.execute_reply": "2022-03-25T00:23:31.776479Z",
     "shell.execute_reply.started": "2022-03-25T00:23:29.931786Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-25 08:23:31,760] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/ernie-1.0/vocab.txt\n"
     ]
    }
   ],
   "source": [
    "from paddlenlp.datasets import MapDataset\n",
    "from paddle.io import BatchSampler, DataLoader\n",
    "from paddlenlp.data import Pad, Stack, Tuple\n",
    "from paddlenlp.transformers import ErnieModel as SeqClfModel\n",
    "from paddlenlp.transformers import ErnieTokenizer as PTMTokenizer\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "MODEL_NAME = \"ernie-1.0\"\n",
    "tokenizer = PTMTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "\n",
    "def example_converter(example, max_seq_length, tokenizer):\n",
    "    text_a, text_b, label = example\n",
    "    encoded = tokenizer(text=text_a, text_pair=text_b, max_seq_len=max_seq_length)\n",
    "    input_ids = encoded[\"input_ids\"]\n",
    "    token_type_ids = encoded[\"token_type_ids\"]\n",
    "    label = np.array([label], dtype=\"int64\")\n",
    "    return input_ids, token_type_ids, label\n",
    "\n",
    "\n",
    "def get_trans_fn(max_seq_length=128, tokenizer=tokenizer):\n",
    "    return lambda ex: example_converter(ex, max_seq_length, tokenizer)\n",
    "\n",
    "\n",
    "batchify_fn = lambda samples, fn=Tuple(\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_id), \n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_type_id),\n",
    "    Stack(dtype=\"int64\")\n",
    "    ): fn(samples)\n",
    "\n",
    "\n",
    "def create_dataloader(dataset, \n",
    "                      trans_fn, \n",
    "                      batchify_fn, \n",
    "                      test=False,\n",
    "                      batch_size=128, \n",
    "                      shuffle=True, \n",
    "                      sampler=BatchSampler):\n",
    "    \n",
    "    if test:\n",
    "        dataset = [d + (0,) for d in dataset]\n",
    "\n",
    "    if not isinstance(dataset, MapDataset):\n",
    "        dataset = MapDataset(dataset)\n",
    "        \n",
    "    dataset.map(trans_fn)\n",
    "    batch_sampler = sampler(dataset, \n",
    "                            shuffle=shuffle, \n",
    "                            batch_size=batch_size)\n",
    "    \n",
    "    dataloder = DataLoader(dataset, \n",
    "                           batch_sampler=batch_sampler, \n",
    "                           collate_fn=batchify_fn)\n",
    "    \n",
    "    return dataloder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T00:23:31.778518Z",
     "iopub.status.busy": "2022-03-25T00:23:31.778189Z",
     "iopub.status.idle": "2022-03-25T00:23:31.784238Z",
     "shell.execute_reply": "2022-03-25T00:23:31.783721Z",
     "shell.execute_reply.started": "2022-03-25T00:23:31.778488Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_seq_length = 128; batch_size = 64\n",
    "trans_fn = get_trans_fn(max_seq_length)\n",
    "train_loader = create_dataloader(train_set, trans_fn, batchify_fn, batch_size=batch_size)\n",
    "# dev_loader = create_dataloader(dev_set, trans_fn, batchify_fn, batch_size=batch_size)\n",
    "test_loader = create_dataloader(test_set, trans_fn, batchify_fn, shuffle=False, test=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T00:23:31.785413Z",
     "iopub.status.busy": "2022-03-25T00:23:31.785005Z",
     "iopub.status.idle": "2022-03-25T00:23:31.791027Z",
     "shell.execute_reply": "2022-03-25T00:23:31.790386Z",
     "shell.execute_reply.started": "2022-03-25T00:23:31.785390Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from paddle import nn\n",
    "import paddle\n",
    "\n",
    "\n",
    "class PTM(nn.Layer):\n",
    "\n",
    "    def __init__(self, pretrained_model, dropout=0.1, num_class=2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.ptm = pretrained_model\n",
    "        ptm_out_dim = self.ptm.config[\"hidden_size\"]\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc1 = nn.Linear(ptm_out_dim, num_class)\n",
    "\n",
    "    def encoder(self, input_ids, token_type_ids):\n",
    "        _, embd = self.ptm(input_ids, token_type_ids)\n",
    "        embd = self.dropout(embd)\n",
    "        return embd\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids):\n",
    "        embd = self.encoder(input_ids, token_type_ids)\n",
    "        logits = self.fc1(embd)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T00:23:31.791891Z",
     "iopub.status.busy": "2022-03-25T00:23:31.791730Z",
     "iopub.status.idle": "2022-03-25T00:23:31.797393Z",
     "shell.execute_reply": "2022-03-25T00:23:31.796868Z",
     "shell.execute_reply.started": "2022-03-25T00:23:31.791872Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from paddlenlp.transformers import LinearDecayWithWarmup\n",
    "\n",
    "epoch = 10\n",
    "weight_decay = 0.0\n",
    "warmup_proportion = 0.0\n",
    "lr_scheduler = LinearDecayWithWarmup(5e-5, len(train_loader) * epoch,\n",
    "                                         warmup_proportion)\n",
    "\n",
    "def get_model(model):\n",
    "    decay_params = [\n",
    "        p.name for n, p in model.named_parameters()\n",
    "        if not any(nd in n for nd in [\"bias\", \"norm\"])\n",
    "    ]\n",
    "    optimizer = paddle.optimizer.AdamW(\n",
    "    parameters=model.parameters(), \n",
    "    learning_rate=lr_scheduler, \n",
    "    weight_decay=weight_decay, \n",
    "    apply_decay_param_fun=lambda x: x in decay_params)\n",
    "\n",
    "    criterion = paddle.nn.CrossEntropyLoss()\n",
    "\n",
    "    model = paddle.Model(model)\n",
    "    metric = paddle.metric.Accuracy()\n",
    "    model.prepare(optimizer, criterion, metric)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T00:23:31.798429Z",
     "iopub.status.busy": "2022-03-25T00:23:31.798116Z",
     "iopub.status.idle": "2022-03-25T00:23:38.234889Z",
     "shell.execute_reply": "2022-03-25T00:23:38.233978Z",
     "shell.execute_reply.started": "2022-03-25T00:23:31.798407Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-03-25 08:23:31,799] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/ernie-1.0/ernie_v1_chn_base.pdparams\n",
      "W0325 08:23:31.802661  7797 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1\n",
      "W0325 08:23:31.807628  7797 device_context.cc:465] device: 0, cuDNN Version: 7.6.\n",
      "[2022-03-25 08:23:37,869] [    INFO] - Weights from pretrained model not used in ErnieModel: ['cls.predictions.layer_norm.weight', 'cls.predictions.decoder_bias', 'cls.predictions.transform.bias', 'cls.predictions.transform.weight', 'cls.predictions.layer_norm.bias']\n"
     ]
    }
   ],
   "source": [
    "ptm = SeqClfModel.from_pretrained(MODEL_NAME)\n",
    "model = PTM(ptm)\n",
    "model = get_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T00:23:38.236469Z",
     "iopub.status.busy": "2022-03-25T00:23:38.236110Z",
     "iopub.status.idle": "2022-03-25T01:16:34.715434Z",
     "shell.execute_reply": "2022-03-25T01:16:34.714819Z",
     "shell.execute_reply.started": "2022-03-25T00:23:38.236434Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous steps.\n",
      "Epoch 1/10\n",
      "step 100/799 - loss: 0.6375 - acc: 0.5906 - 396ms/step\n",
      "step 200/799 - loss: 0.5679 - acc: 0.6795 - 397ms/step\n",
      "step 300/799 - loss: 0.2788 - acc: 0.7279 - 396ms/step\n",
      "step 400/799 - loss: 0.4233 - acc: 0.7579 - 396ms/step\n",
      "step 500/799 - loss: 0.3408 - acc: 0.7760 - 396ms/step\n",
      "step 600/799 - loss: 0.2779 - acc: 0.7916 - 396ms/step\n",
      "step 700/799 - loss: 0.2776 - acc: 0.8031 - 397ms/step\n",
      "step 799/799 - loss: 0.2029 - acc: 0.8116 - 397ms/step\n",
      "Epoch 2/10\n",
      "step 100/799 - loss: 0.2308 - acc: 0.9114 - 396ms/step\n",
      "step 200/799 - loss: 0.1756 - acc: 0.9073 - 394ms/step\n",
      "step 300/799 - loss: 0.0685 - acc: 0.9093 - 395ms/step\n",
      "step 400/799 - loss: 0.2880 - acc: 0.9089 - 396ms/step\n",
      "step 500/799 - loss: 0.2351 - acc: 0.9088 - 398ms/step\n",
      "step 600/799 - loss: 0.3234 - acc: 0.9097 - 398ms/step\n",
      "step 700/799 - loss: 0.2408 - acc: 0.9098 - 398ms/step\n",
      "step 799/799 - loss: 0.1434 - acc: 0.9101 - 397ms/step\n",
      "Epoch 3/10\n",
      "step 100/799 - loss: 0.1224 - acc: 0.9419 - 399ms/step\n",
      "step 200/799 - loss: 0.1115 - acc: 0.9404 - 397ms/step\n",
      "step 300/799 - loss: 0.1941 - acc: 0.9397 - 398ms/step\n",
      "step 400/799 - loss: 0.1338 - acc: 0.9396 - 398ms/step\n",
      "step 500/799 - loss: 0.1139 - acc: 0.9401 - 397ms/step\n",
      "step 600/799 - loss: 0.2271 - acc: 0.9402 - 397ms/step\n",
      "step 700/799 - loss: 0.1362 - acc: 0.9400 - 397ms/step\n",
      "step 799/799 - loss: 0.1743 - acc: 0.9398 - 397ms/step\n",
      "Epoch 4/10\n",
      "step 100/799 - loss: 0.1617 - acc: 0.9602 - 399ms/step\n",
      "step 200/799 - loss: 0.2607 - acc: 0.9613 - 398ms/step\n",
      "step 300/799 - loss: 0.0647 - acc: 0.9594 - 398ms/step\n",
      "step 400/799 - loss: 0.1776 - acc: 0.9595 - 398ms/step\n",
      "step 500/799 - loss: 0.1000 - acc: 0.9596 - 398ms/step\n",
      "step 600/799 - loss: 0.0408 - acc: 0.9588 - 398ms/step\n",
      "step 700/799 - loss: 0.1013 - acc: 0.9588 - 398ms/step\n",
      "step 799/799 - loss: 0.0929 - acc: 0.9584 - 398ms/step\n",
      "Epoch 5/10\n",
      "step 100/799 - loss: 0.0221 - acc: 0.9741 - 399ms/step\n",
      "step 200/799 - loss: 0.1915 - acc: 0.9738 - 398ms/step\n",
      "step 300/799 - loss: 0.1865 - acc: 0.9724 - 398ms/step\n",
      "step 400/799 - loss: 0.0490 - acc: 0.9718 - 398ms/step\n",
      "step 500/799 - loss: 0.0701 - acc: 0.9715 - 397ms/step\n",
      "step 600/799 - loss: 0.0898 - acc: 0.9707 - 397ms/step\n",
      "step 700/799 - loss: 0.1220 - acc: 0.9704 - 397ms/step\n",
      "step 799/799 - loss: 0.1052 - acc: 0.9706 - 397ms/step\n",
      "Epoch 6/10\n",
      "step 100/799 - loss: 0.0180 - acc: 0.9839 - 399ms/step\n",
      "step 200/799 - loss: 0.0069 - acc: 0.9841 - 399ms/step\n",
      "step 300/799 - loss: 0.0131 - acc: 0.9828 - 398ms/step\n",
      "step 400/799 - loss: 0.0193 - acc: 0.9821 - 398ms/step\n",
      "step 500/799 - loss: 0.1369 - acc: 0.9812 - 398ms/step\n",
      "step 600/799 - loss: 0.0433 - acc: 0.9807 - 399ms/step\n",
      "step 700/799 - loss: 0.0326 - acc: 0.9804 - 398ms/step\n",
      "step 799/799 - loss: 0.0400 - acc: 0.9802 - 398ms/step\n",
      "Epoch 7/10\n",
      "step 100/799 - loss: 0.0105 - acc: 0.9881 - 401ms/step\n",
      "step 200/799 - loss: 0.1028 - acc: 0.9873 - 399ms/step\n",
      "step 300/799 - loss: 0.0330 - acc: 0.9872 - 399ms/step\n",
      "step 400/799 - loss: 0.1180 - acc: 0.9863 - 399ms/step\n",
      "step 500/799 - loss: 0.0817 - acc: 0.9859 - 399ms/step\n",
      "step 600/799 - loss: 0.0087 - acc: 0.9857 - 399ms/step\n",
      "step 700/799 - loss: 0.1050 - acc: 0.9854 - 399ms/step\n",
      "step 799/799 - loss: 0.0506 - acc: 0.9849 - 399ms/step\n",
      "Epoch 8/10\n",
      "step 100/799 - loss: 0.0187 - acc: 0.9892 - 399ms/step\n",
      "step 200/799 - loss: 0.0188 - acc: 0.9903 - 398ms/step\n",
      "step 300/799 - loss: 0.0025 - acc: 0.9899 - 398ms/step\n",
      "step 400/799 - loss: 0.0012 - acc: 0.9892 - 397ms/step\n",
      "step 500/799 - loss: 0.0024 - acc: 0.9887 - 398ms/step\n",
      "step 600/799 - loss: 0.0085 - acc: 0.9888 - 397ms/step\n",
      "step 700/799 - loss: 0.0604 - acc: 0.9890 - 397ms/step\n",
      "step 799/799 - loss: 0.0306 - acc: 0.9887 - 397ms/step\n",
      "Epoch 9/10\n",
      "step 100/799 - loss: 0.0165 - acc: 0.9908 - 398ms/step\n",
      "step 200/799 - loss: 0.0070 - acc: 0.9913 - 399ms/step\n",
      "step 300/799 - loss: 0.0751 - acc: 0.9914 - 398ms/step\n",
      "step 400/799 - loss: 0.0603 - acc: 0.9912 - 399ms/step\n",
      "step 500/799 - loss: 0.0016 - acc: 0.9915 - 398ms/step\n",
      "step 600/799 - loss: 0.0097 - acc: 0.9915 - 398ms/step\n",
      "step 700/799 - loss: 0.0038 - acc: 0.9915 - 398ms/step\n",
      "step 799/799 - loss: 0.0478 - acc: 0.9913 - 398ms/step\n",
      "Epoch 10/10\n",
      "step 100/799 - loss: 0.0379 - acc: 0.9922 - 399ms/step\n",
      "step 200/799 - loss: 7.9425e-04 - acc: 0.9924 - 400ms/step\n",
      "step 300/799 - loss: 7.9435e-04 - acc: 0.9932 - 400ms/step\n",
      "step 400/799 - loss: 0.0018 - acc: 0.9937 - 400ms/step\n",
      "step 500/799 - loss: 0.0038 - acc: 0.9933 - 400ms/step\n",
      "step 600/799 - loss: 0.0024 - acc: 0.9935 - 399ms/step\n",
      "step 700/799 - loss: 0.0022 - acc: 0.9934 - 399ms/step\n",
      "step 799/799 - loss: 0.0242 - acc: 0.9934 - 398ms/step\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_loader, epochs=epoch, verbose=2, log_freq=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T01:16:34.718043Z",
     "iopub.status.busy": "2022-03-25T01:16:34.717572Z",
     "iopub.status.idle": "2022-03-25T01:16:39.934264Z",
     "shell.execute_reply": "2022-03-25T01:16:39.933444Z",
     "shell.execute_reply.started": "2022-03-25T01:16:34.718014Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict begin...\n",
      "step 32/32 [==============================] - ETA: 6s - 229ms/st - ETA: 5s - 197ms/st - ETA: 4s - 187ms/st - ETA: 4s - 182ms/st - ETA: 3s - 179ms/st - ETA: 3s - 176ms/st - ETA: 3s - 175ms/st - ETA: 2s - 173ms/st - ETA: 2s - 173ms/st - ETA: 2s - 171ms/st - ETA: 1s - 171ms/st - ETA: 1s - 171ms/st - ETA: 1s - 171ms/st - ETA: 0s - 170ms/st - ETA: 0s - 167ms/st - 163ms/step          \n",
      "Predict samples: 2000\n"
     ]
    }
   ],
   "source": [
    "import paddle.nn.functional as F\n",
    "\n",
    "\n",
    "predictions = []\n",
    "logits = model.predict(test_loader)\n",
    "\n",
    "for batch in logits[0]:\n",
    "    batch = paddle.to_tensor(batch)\n",
    "    probs = F.softmax(batch, axis=1)\n",
    "    preds = paddle.argmax(probs, axis=1).numpy().tolist()\n",
    "    predictions.extend(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-25T01:16:39.936033Z",
     "iopub.status.busy": "2022-03-25T01:16:39.935472Z",
     "iopub.status.idle": "2022-03-25T01:16:39.941274Z",
     "shell.execute_reply": "2022-03-25T01:16:39.940475Z",
     "shell.execute_reply.started": "2022-03-25T01:16:39.936003Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('paws-x.tsv', 'w') as f:\n",
    "    f.write(\"index\\tprediction\")\n",
    "    for idx, p in enumerate(predictions):\n",
    "        f.write(f\"\\n{idx}\\t{p}\")\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
